{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b5c0d2440b3e4995a794ded565213150","deepnote_cell_type":"markdown"},"source":["<h1><center>Laboratorio 9: Optimización de modelos 💯</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"]},{"cell_type":"markdown","metadata":{"cell_id":"bfb94b9656f145ad83e81b75d218cb70","deepnote_cell_type":"markdown"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Ignacio Meza, Gabriel Iturra\n","- Auxiliar: Sebastián Tinoco\n","- Ayudante: Arturo Lazcano, Angelo Muñoz"]},{"cell_type":"markdown","metadata":{"cell_id":"b1b537fdd27c43909a49d3476ce64d91","deepnote_cell_type":"markdown"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n","\n","- Nombre de alumno 1: Nicolás Becerra\n","- Nombre de alumno 2: Simón Sanfeliú\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b7dbdd30ab544cb8a8afe00648a586ae","deepnote_cell_type":"markdown"},"source":["## Temas a tratar\n","\n","- Predicción de demanda usando `xgboost`\n","- Búsqueda del modelo óptimo de clasificación usando `optuna`\n","- Uso de pipelines.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer material del curso que estimen conveniente.\n","\n","### Objetivos principales del laboratorio\n","\n","- Optimizar modelos usando `optuna`\n","- Recurrir a técnicas de *prunning*\n","- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n","- Fijar un pipeline con un modelo base que luego se irá optimizando.\n","\n","El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."]},{"cell_type":"markdown","metadata":{"cell_id":"f38c8342f5164aa992a97488dd5590bf","deepnote_cell_type":"markdown"},"source":["### **Link de repositorio de GitHub:** https://github.com/SimonSanfeliu/MDS7202-BS/tree/L9"]},{"cell_type":"markdown","metadata":{"cell_id":"f1c73babb7f74af588a4fa6ae14829e0","deepnote_cell_type":"markdown"},"source":["# Importamos librerias útiles"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"51afe4d2df42442b9e5402ffece60ead","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4957,"execution_start":1699544354044,"source_hash":null},"outputs":[],"source":["!pip install -qq xgboost optuna"]},{"cell_type":"markdown","metadata":{"cell_id":"44d227389a734ac59189c5e0005bc68a","deepnote_cell_type":"markdown"},"source":["# 1. El emprendimiento de Fiu\n","\n","Tras liderar de manera exitosa la implementación de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corpóreo **Fiu** se anima y decide levantar su propio negocio de consultoría en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterización de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n","\n","Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n","\n","Para comenzar, cargue el dataset señalado y visualice a través de un `.head` los atributos que posee el dataset.\n","\n","<i><p align=\"center\">Fiu siendo felicitado por su excelente desempeño en el proyecto de caracterización de datos</p></i>\n","<p align=\"center\">\n","  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n","</p>"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"2f9c82d204b14515ad27ae07e0b77702","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":92,"execution_start":1699544359006,"source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\sanfe\\AppData\\Local\\Temp\\ipykernel_3380\\3184305967.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df['date'] = pd.to_datetime(df['date'])\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>city</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>pop</th>\n","      <th>shop</th>\n","      <th>brand</th>\n","      <th>container</th>\n","      <th>capacity</th>\n","      <th>price</th>\n","      <th>quantity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>0.96</td>\n","      <td>13280</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>plastic</td>\n","      <td>1.5lt</td>\n","      <td>2.86</td>\n","      <td>6727</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.87</td>\n","      <td>9848</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>1.00</td>\n","      <td>20050</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.39</td>\n","      <td>25696</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id       date    city       lat      long     pop    shop        brand  \\\n","0   0 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","1   1 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","2   2 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","3   3 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","4   4 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","\n","  container capacity  price  quantity  \n","0     glass    500ml   0.96     13280  \n","1   plastic    1.5lt   2.86      6727  \n","2       can    330ml   0.87      9848  \n","3     glass    500ml   1.00     20050  \n","4       can    330ml   0.39     25696  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","\n","df = pd.read_csv('sales.csv')\n","df['date'] = pd.to_datetime(df['date'])\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"cell_id":"b50db6f2cb804932ae3f9e5748a6ea61","deepnote_cell_type":"markdown"},"source":["## 1.1 Generando un Baseline (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n","</p>\n","\n","Antes de entrenar un algoritmo, usted recuerda los apuntes de su magíster en ciencia de datos y recuerda que debe seguir una serie de *buenas prácticas* para entrenar correcta y debidamente su modelo. Después de un par de vueltas, llega a las siguientes tareas:\n","\n","1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n","2. Implemente un `FunctionTransformer` para extraer el día, mes y año de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n","3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos numéricos y categóricos. Use `OneHotEncoder` para las variables categóricas.\n","4. Guarde los pasos anteriores en un `Pipeline`, dejando como último paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n","5. Entrene el pipeline anterior y reporte la métrica `mean_absolute_error` sobre los datos de validación. ¿Cómo se interpreta esta métrica para el contexto del negocio?\n","6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los parámetros por default**. ¿Cómo cambia el MAE al implementar este algoritmo? ¿Es mejor o peor que el `DummyRegressor`?\n","7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Función para FunctionTransformer\n","def extract_date(df):\n","    \"\"\"\n","    Genera las columnas de año, mes y día a partir de una columna de fechas.\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        DataFrame con la columna de fechas.\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        DataFrame con las columnas de año, mes y día.\n","    \"\"\"\n","    # Revisando datos\n","    assert type(df) == pd.DataFrame\n","    assert \"date\" in df.columns\n","\n","    # Generando las columnas\n","    df = df.assign(\n","        year = [d.year for d in df[\"date\"].dt.date],\n","        month = [d.month for d in df[\"date\"].dt.date],\n","        day = [d.day for d in df[\"date\"].dt.date]\n","    )\n","\n","    # Transformándolas en categorías\n","    df = df.astype(\n","        {\n","            \"day\": \"category\",\n","            \"month\": \"category\",\n","            \"year\": \"category\"\n","        }\n","    )\n","\n","    return df\n","\n","# Función para transformación logarítmica\n","def to_log(df_s):\n","    \"\"\"\n","    Aplica una transformación logarítimica a una serie de datos.\n","\n","    Parameters\n","    ----------\n","    df_s : pd.Series\n","        Serie de datos a transformar.\n","\n","    Returns\n","    -------\n","    pd.Series\n","        Serie de datos transformada. \n","    \"\"\"\n","    # Revisando datos\n","    assert type(df_s) == pd.DataFrame\n","\n","    # Transformando los datos de la serie a escala logarítmica\n","    df_s = df_s.apply(lambda x: np.log(x + 1))\n","    return df_s"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"1482c992d9494e5582b23dbd3431dbfd","deepnote_cell_type":"code"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n","                  transformers=[(&#x27;Categorico&#x27;,\n","                                 Pipeline(steps=[(&#x27;Encoder&#x27;,\n","                                                  OneHotEncoder(sparse_output=False))]),\n","                                 [&#x27;date&#x27;, &#x27;city&#x27;, &#x27;shop&#x27;, &#x27;brand&#x27;, &#x27;container&#x27;,\n","                                  &#x27;capacity&#x27;, &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;]),\n","                                (&#x27;Numerico&#x27;,\n","                                 Pipeline(steps=[(&#x27;Logaritmic scaler&#x27;,\n","                                                  FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;,\n","                                                                      func=&lt;function to_log at 0x0000018E4D030B80&gt;)),\n","                                                 (&#x27;MinMax scaler&#x27;,\n","                                                  MinMaxScaler())]),\n","                                 [&#x27;lat&#x27;, &#x27;long&#x27;, &#x27;pop&#x27;, &#x27;price&#x27;])],\n","                  verbose_feature_names_out=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n","                  transformers=[(&#x27;Categorico&#x27;,\n","                                 Pipeline(steps=[(&#x27;Encoder&#x27;,\n","                                                  OneHotEncoder(sparse_output=False))]),\n","                                 [&#x27;date&#x27;, &#x27;city&#x27;, &#x27;shop&#x27;, &#x27;brand&#x27;, &#x27;container&#x27;,\n","                                  &#x27;capacity&#x27;, &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;]),\n","                                (&#x27;Numerico&#x27;,\n","                                 Pipeline(steps=[(&#x27;Logaritmic scaler&#x27;,\n","                                                  FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;,\n","                                                                      func=&lt;function to_log at 0x0000018E4D030B80&gt;)),\n","                                                 (&#x27;MinMax scaler&#x27;,\n","                                                  MinMaxScaler())]),\n","                                 [&#x27;lat&#x27;, &#x27;long&#x27;, &#x27;pop&#x27;, &#x27;price&#x27;])],\n","                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Categorico</label><div class=\"sk-toggleable__content\"><pre>[&#x27;date&#x27;, &#x27;city&#x27;, &#x27;shop&#x27;, &#x27;brand&#x27;, &#x27;container&#x27;, &#x27;capacity&#x27;, &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Numerico</label><div class=\"sk-toggleable__content\"><pre>[&#x27;lat&#x27;, &#x27;long&#x27;, &#x27;pop&#x27;, &#x27;price&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;,\n","                    func=&lt;function to_log at 0x0000018E4D030B80&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["ColumnTransformer(remainder='passthrough',\n","                  transformers=[('Categorico',\n","                                 Pipeline(steps=[('Encoder',\n","                                                  OneHotEncoder(sparse_output=False))]),\n","                                 ['date', 'city', 'shop', 'brand', 'container',\n","                                  'capacity', 'year', 'month', 'day']),\n","                                ('Numerico',\n","                                 Pipeline(steps=[('Logaritmic scaler',\n","                                                  FunctionTransformer(feature_names_out='one-to-one',\n","                                                                      func=<function to_log at 0x0000018E4D030B80>)),\n","                                                 ('MinMax scaler',\n","                                                  MinMaxScaler())]),\n","                                 ['lat', 'long', 'pop', 'price'])],\n","                  verbose_feature_names_out=False)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Obteniendo librerías necesarias\n","from sklearn.model_selection import train_test_split \n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.dummy import DummyRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","# Definiendo la semilla\n","RANDOM_STATE = 42\n","\n","# Separando el conjunto de datos\n","X_train, X_rest, y_train, y_rest = train_test_split(df, df[\"quantity\"], test_size=.3, random_state=RANDOM_STATE)\n","X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=.33, random_state=RANDOM_STATE)\n","X_train.drop(columns=[\"id\", \"quantity\"], inplace=True)\n","X_val.drop(columns=[\"id\", \"quantity\"], inplace=True)\n","X_test.drop(columns=[\"id\", \"quantity\"], inplace=True)\n","\n","# Separando los datos en numéricos y categóricos\n","num_cols = X_train.corr(numeric_only=True).columns.to_list()\n","cat_cols = [col for col in X_train.columns if not col in num_cols]\n","cat_cols.append(\"year\")  # Agregando las nuevas columnas que se obtendrán del FunctionTransformer\n","cat_cols.append(\"month\")\n","cat_cols.append(\"day\")\n","\n","# Atributos numéricos\n","num_pipe = Pipeline([\n","                ('Logaritmic scaler', FunctionTransformer(to_log, feature_names_out='one-to-one')),\n","                ('MinMax scaler', MinMaxScaler())\n","            ])\n","# Atributos categóricos\n","cat_pipe = Pipeline([\n","    ('Encoder', OneHotEncoder(sparse_output=False))\n","])\n","\n","# Creando ColumnTransformer\n","ctrans = ColumnTransformer(\n","        transformers=[\n","            (\"Categorico\", cat_pipe, cat_cols),\n","            (\"Numerico\", num_pipe, num_cols),\n","        ],\n","        remainder=\"passthrough\",\n","        verbose_feature_names_out=False\n",")\n","ctrans.set_output(transform='pandas')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE sobre conjunto de validación: 13308.134750658153\n"]}],"source":["# Pipeline de entrenamiento 1\n","pipe_train1 = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans),\n","    (\"Classifier\", DummyRegressor())\n","])\n","\n","# Entrenando\n","model1 = pipe_train1.fit(X_train, y_train)\n","\n","# Prediciendo\n","y_pred1 = model1.predict(X_val)\n","\n","# MAE\n","mae1 = mean_absolute_error(y_val, y_pred1)\n","print(f\"MAE sobre conjunto de validación: {mae1}\")"]},{"cell_type":"markdown","metadata":{},"source":["> El `mean_absolute_error` es una medida de diferencia entre el valor predicho y el valor real, siendo ésta el error absoluto medio entre ambos. Lo ideal es que esta métrica sea lo más cercana a 0 posible, ya que implicaría que el valor predicho no dista mucho del real, por lo que se tendría una buena predicción. \n","\n","> Dado que el valor obtenido del MAE es alrededor de 13000, se tiene que para la pipeline generada con `DummyRegressor` es de muy baja calidad, ya que los valores predichos están muy alejados de los valores reales. Así, se tiene que el primer modelo generado es muy malo para la predicción de la demanda de cantidad de ventas, por lo que la métrica estaría diciendo que este modelo no es bueno para el negocio."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE sobre conjunto de validación: 2500.3221446955317\n"]}],"source":["import xgboost as xgb\n","\n","# Pipeline de entrenamiento 2\n","pipe_train2 = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans),\n","    (\"Classifier\", xgb.XGBRegressor())\n","])\n","\n","# Entrenando\n","model2 = pipe_train2.fit(X_train, y_train)\n","\n","# Prediciendo\n","y_pred2 = model2.predict(X_val)\n","\n","# MAE\n","mae2 = mean_absolute_error(y_val, y_pred2)\n","print(f\"MAE sobre conjunto de validación: {mae2}\")"]},{"cell_type":"markdown","metadata":{},"source":["> Al cambiar el `DummyRegressor` por el `XGBRegressor`, se tiene una mejora instantánea en la métrica, teniendo ahora un MAE de cerca de 2500, lo que es mucho más cercano a 0 que 13000. Este valor sigue indicando que el clasificador es malo para el negocio, pero muestra una inmediata mejora con el anterior."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["['models/default_xgb_model.pkl']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import joblib\n","\n","# Creando la carpeta de los modelos si es que no existe\n","if not os.path.exists(\"models\"):\n","    os.mkdir(\"models\")\n","\n","# Guardando los archivos en pkls separados\n","joblib.dump(model1, \"models/dummy_model.pkl\")\n","joblib.dump(model2, \"models/default_xgb_model.pkl\")"]},{"cell_type":"markdown","metadata":{"cell_id":"7e17e46063774ec28226fe300d42ffe0","deepnote_cell_type":"markdown"},"source":["## 1.2 Forzando relaciones entre parámetros con XGBoost (1.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n","</p>\n","\n","Un colega aficionado a la economía le *sopla* que la demanda guarda una relación inversa con el precio del producto. Motivado para impresionar al querido corpóreo, se propone hacer uso de esta información para mejorar su modelo.\n","\n","Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relación monótona negativa entre el precio y la cantidad. Luego, vuelva a reportar el `MAE` sobre el conjunto de validación. ¿Cómo cambia el error al incluir esta relación? ¿Tenía razón su amigo?\n","\n","Nuevamente, guarde su modelo en un archivo .pkl\n","\n","Nota: Para realizar esta parte, debe apoyarse en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentación</a>.\n","\n","Hint: Para implementar el constraint, se le sugiere hacerlo especificando el nombre de la variable. De ser así, probablemente le sea útil **mantener el formato de pandas** antes del step de entrenamiento."]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"f469f3b572be434191d2d5c3f11b20d2","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE sobre conjunto de validación: 2707.9117589321568\n"]}],"source":["# Pipeline de entrenamiento 3\n","pipe_train3 = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans),\n","    (\"Classifier\", xgb.XGBRegressor(monotone_constraints={'price': -1}))\n","])\n","\n","# Entrenando\n","model3 = pipe_train3.fit(X_train, y_train)\n","\n","# Prediciendo\n","y_pred3 = model3.predict(X_val)\n","\n","# MAE\n","mae3 = mean_absolute_error(y_val, y_pred3)\n","print(f\"MAE sobre conjunto de validación: {mae3}\")"]},{"cell_type":"markdown","metadata":{},"source":["> Al incluir esta relación, el error aumentó, lo que indica que empeoró el modelo. Esto es esperable, puesto que, mientras que es cierto que la demanda por lo general disminuye al momento de aumentar los precios, esta relación no es lineal. Esto quiere decir que no es directa la relación inversa que tienen, por lo que al definirla así, se tiene que el modelo empeorará ya que no es el comportamiento real de la demanda el que se estaría modelando, sino que una simplificación muy grande de éste."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["['models/constraint_xgb_model.pkl']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Guardando el modelo\n","joblib.dump(model3, \"models/constraint_xgb_model.pkl\")"]},{"cell_type":"markdown","metadata":{"cell_id":"e59ef80ed20b4de8921f24da74e87374","deepnote_cell_type":"markdown"},"source":["## 1.3 Optimización de Hiperparámetros con Optuna (2.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n","</p>\n","\n","Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun más* su modelo. En particular, le comenta de la optimización de hiperparámetros con metodologías bayesianas a través del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n","\n","A partir de la mejor configuración obtenida en la sección anterior, utilice `optuna` para optimizar sus hiperparámetros. En particular, se le pide:\n","\n","- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n","- Utilice `TPESampler` como método de muestreo\n","- De `XGBRegressor`, optimice los siguientes hiperparámetros:\n","    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n","    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n","    - `max_depth` buscando valores enteros en el rango (3, 10)\n","    - `max_leaves` buscando valores enteros en el rango (0, 100)\n","    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n","    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n","    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n","- De `OneHotEncoder`, optimice el hiperparámetro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n","- Explique cada hiperparámetro y su rol en el modelo. ¿Hacen sentido los rangos de optimización indicados?\n","- Fije el tiempo de entrenamiento a 5 minutos\n","- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n","- Guardar su modelo en un archivo .pkl"]},{"cell_type":"markdown","metadata":{},"source":["**Explicaciones de los hiperparámetros**\n","\n","* `min_frequency`: Es la frecuencia mínima que debe tener una categoría para que se considere en el modelo. Al ser un flotante, corresponde al porcentaje de frecuencia mínimo para considerarlo y se obtiene multiplicando este parámetro con el número de muestras.\n","* `learning_rate`: El learning rate corresponde al tamaño de paso que se da en cada iteración del algoritmo. Este valor es multiplicado por el gradiente de la función de pérdida, por lo que se tiene que, mientras más pequeño sea este valor, más pequeño será el paso que se da en cada iteración y más tardará el entrenamiento. El rango es adecuado para este hiperparámetro, siendo 0.1 un máximo bien razonable dentro del entrenamiento.\n","* `n_estimators`: El número de estimadores corresponde a la cantidad de árboles que se construyen en el algoritmo. De esta manera, se tiene que, mientras más grande sea este valor, más complejo será el modelo y más tardará el entrenamiento. El rango hace sentido ya que son enteros, \n","* `max_depth`: Es la profundidad de cada árbol. En cierta forma, es la cantidad de preguntas que se le hacen al modelo para que éste pueda predecir. La profundidad entre 3 y 10 resulta coherente, ya que se tiene que, mientras más profundo sea el árbol, más complejo será el modelo y más tardará el entrenamiento, por lo que 10 resulta razonable como un máximo de capas.\n","* `max_leaves`: Corresponde al número máximo de hojas del árbol resultante. De cierta manera, regula la complejidad del modelo al igual que max_depth, pero de una manera más directa. El rango es razonable; sin embargo, se recomienda que sea menor a 64 para no ralentizar el entrenamiento demasiado.\n","* `min_child_weight`: Es el peso mínimo que debe tener un nodo para que se divida. Este hiperparámetro regula la complejidad del modelo, ya que mientras más grande sea este valor, más nodos se descartarán y más simple será el modelo. Debido a la naturaleza del modelo, el rango es adecuado, aunque incluso existen algunos modelos donde 200 sea un valor razonable.\n","* `reg_alpha`: Regularización L1 a los pesos de los nodos. Este penaliza el valor absoluto de los pesos o coeficientes, ayudando a hacer el modelo más robusto y evitar el esparcimiento al promover que algunos pesos de anulen al ser menos importantes. El rango de este varia entre 0 y 1, siendo 0 una penalización nula.\n","* `reg_lambda`: Regularización L2 a los pesos de los nodos. Este penaliza el valor cuadrático de los pesos o coeficientes, lo que ayuda a prevenir el overfitting al suavizar los pesos que se escapan del resto, limitando la magnitud de ellos. El rango de este varia entre 0 y 1, siendo 0 una penalización nula, al igual que el anterior."]},{"cell_type":"code","execution_count":11,"metadata":{"cell_id":"de5914621cc64cb0b1bacb9ff565a97e","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\sanfe\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# Creando la optimización con Optuna\n","import optuna\n","\n","def objective(trial):\n","    \"\"\"\n","    Función objetivo para optimizar los hiperparámetros del modelo. Utiliza la libreria Optuna.\n","\n","    Parameters\n","    ----------\n","    trial : optuna.trial._trial.Trial\n","        Objeto de la clase Trial de Optuna.\n","\n","    Returns\n","    -------\n","    mae_opt : float\n","        Error absoluto medio del modelo optimizado. Es el valor que se intenta minimizar.\n","    \"\"\"\n","    # Agregando valores a probar\n","    min_frequency = trial.suggest_float('min_frequency', 0, 1)\n","    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1)\n","    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n","    max_depth = trial.suggest_int('max_depth', 3, 10)\n","    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n","    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n","    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n","    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n","\n","    # Re-editando el OneHotEncoder de ColumnTransformer\n","    cat_pipe = Pipeline([\n","        ('Encoder', OneHotEncoder(min_frequency=min_frequency, sparse_output=False))\n","    ])\n","\n","    ctrans = ColumnTransformer(\n","            transformers=[\n","                (\"Categorico\", cat_pipe, cat_cols),\n","                (\"Numerico\", num_pipe, num_cols),\n","            ],\n","            remainder=\"passthrough\",\n","            verbose_feature_names_out=False\n","    )\n","    ctrans.set_output(transform='pandas')\n","\n","    # Mejor de los 3 pipelines anteriores: pipeline 2\n","    pipe_train2 = Pipeline([\n","        (\"Date extraction\", FunctionTransformer(extract_date)),\n","        (\"Scaling\", ctrans),\n","        (\"Classifier\", xgb.XGBRegressor(learning_rate=learning_rate,\n","                                        n_estimators=n_estimators,\n","                                        max_depth=max_depth,\n","                                        max_leaves=max_leaves,\n","                                        min_child_weight=min_child_weight,\n","                                        reg_alpha=reg_alpha,\n","                                        reg_lambda=reg_lambda))\n","    ])\n","\n","    # Entrenando el pipeline\n","    model_opt = pipe_train2.fit(X_train, y_train)\n","\n","    # Prediciendo\n","    y_pred_opt = model_opt.predict(X_val)\n","\n","    # Obteniendo el MAE\n","    mae_opt = mean_absolute_error(y_val, y_pred_opt)\n","\n","    return mae_opt"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-11-16 23:24:32,435] A new study created in memory with name: no-name-925c7de2-9857-47d5-961d-cb07ebe0b09a\n","[I 2023-11-16 23:24:36,697] Trial 0 finished with value: 9126.717615023155 and parameters: {'min_frequency': 0.5488135039273248, 'learning_rate': 0.07180374727086954, 'n_estimators': 623, 'max_depth': 7, 'max_leaves': 42, 'min_child_weight': 4, 'reg_alpha': 0.4375872112626925, 'reg_lambda': 0.8917730007820798}. Best is trial 0 with value: 9126.717615023155.\n","[I 2023-11-16 23:24:40,846] Trial 1 finished with value: 8930.980045333883 and parameters: {'min_frequency': 0.9636627605010293, 'learning_rate': 0.038960710363751996, 'n_estimators': 802, 'max_depth': 7, 'max_leaves': 57, 'min_child_weight': 5, 'reg_alpha': 0.07103605819788694, 'reg_lambda': 0.08712929970154071}. Best is trial 1 with value: 8930.980045333883.\n","[I 2023-11-16 23:24:48,475] Trial 2 finished with value: 2017.3263964582986 and parameters: {'min_frequency': 0.02021839744032572, 'learning_rate': 0.08342936470924586, 'n_estimators': 790, 'max_depth': 9, 'max_leaves': 98, 'min_child_weight': 4, 'reg_alpha': 0.46147936225293185, 'reg_lambda': 0.7805291762864555}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:49,907] Trial 3 finished with value: 5743.61294095252 and parameters: {'min_frequency': 0.11827442586893322, 'learning_rate': 0.06435218111142486, 'n_estimators': 186, 'max_depth': 10, 'max_leaves': 52, 'min_child_weight': 3, 'reg_alpha': 0.26455561210462697, 'reg_lambda': 0.7742336894342167}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:50,608] Trial 4 finished with value: 8393.085915986941 and parameters: {'min_frequency': 0.45615033221654855, 'learning_rate': 0.05727496093799621, 'n_estimators': 67, 'max_depth': 7, 'max_leaves': 61, 'min_child_weight': 4, 'reg_alpha': 0.9437480785146242, 'reg_lambda': 0.6818202991034834}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:52,457] Trial 5 finished with value: 8388.83419461626 and parameters: {'min_frequency': 0.359507900573786, 'learning_rate': 0.044266163426134805, 'n_estimators': 713, 'max_depth': 3, 'max_leaves': 67, 'min_child_weight': 4, 'reg_alpha': 0.2103825610738409, 'reg_lambda': 0.1289262976548533}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:55,522] Trial 6 finished with value: 6713.059357137642 and parameters: {'min_frequency': 0.31542835092418386, 'learning_rate': 0.03700736632331964, 'n_estimators': 592, 'max_depth': 6, 'max_leaves': 99, 'min_child_weight': 1, 'reg_alpha': 0.2088767560948347, 'reg_lambda': 0.16130951788499626}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:57,151] Trial 7 finished with value: 8326.14631911559 and parameters: {'min_frequency': 0.6531083254653984, 'learning_rate': 0.02607586865143843, 'n_estimators': 493, 'max_depth': 4, 'max_leaves': 16, 'min_child_weight': 1, 'reg_alpha': 0.6563295894652734, 'reg_lambda': 0.1381829513486138}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:59,768] Trial 8 finished with value: 5657.757001339514 and parameters: {'min_frequency': 0.1965823616800535, 'learning_rate': 0.03750379189543545, 'n_estimators': 830, 'max_depth': 3, 'max_leaves': 84, 'min_child_weight': 1, 'reg_alpha': 0.9764594650133958, 'reg_lambda': 0.4686512016477016}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:25:01,593] Trial 9 finished with value: 8437.767673629944 and parameters: {'min_frequency': 0.9767610881903371, 'learning_rate': 0.060879706454759555, 'n_estimators': 753, 'max_depth': 3, 'max_leaves': 28, 'min_child_weight': 1, 'reg_alpha': 0.29614019752214493, 'reg_lambda': 0.11872771895424405}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:25:04,478] Trial 10 finished with value: 4942.809655488731 and parameters: {'min_frequency': 0.020334471624930517, 'learning_rate': 0.09852046649678155, 'n_estimators': 956, 'max_depth': 10, 'max_leaves': 2, 'min_child_weight': 3, 'reg_alpha': 0.6022694078738563, 'reg_lambda': 0.9644831755618566}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:25:08,121] Trial 11 finished with value: 2783.72975743374 and parameters: {'min_frequency': 0.013048945064446538, 'learning_rate': 0.09939800254634318, 'n_estimators': 950, 'max_depth': 10, 'max_leaves': 6, 'min_child_weight': 3, 'reg_alpha': 0.6038510599523575, 'reg_lambda': 0.9940070913069738}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:25:16,935] Trial 12 finished with value: 1986.8998327522634 and parameters: {'min_frequency': 0.013057447356600709, 'learning_rate': 0.09745282164666788, 'n_estimators': 954, 'max_depth': 9, 'max_leaves': 81, 'min_child_weight': 2, 'reg_alpha': 0.498167285369409, 'reg_lambda': 0.9859882238544003}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:20,406] Trial 13 finished with value: 6728.731746250861 and parameters: {'min_frequency': 0.19863360395318855, 'learning_rate': 0.08492643336476893, 'n_estimators': 434, 'max_depth': 9, 'max_leaves': 97, 'min_child_weight': 2, 'reg_alpha': 0.4641406064936066, 'reg_lambda': 0.789372499594353}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:28,060] Trial 14 finished with value: 1996.233344328897 and parameters: {'min_frequency': 0.021305415485054713, 'learning_rate': 0.07831117261323023, 'n_estimators': 973, 'max_depth': 8, 'max_leaves': 81, 'min_child_weight': 2, 'reg_alpha': 0.40751281926357574, 'reg_lambda': 0.6129243749793609}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:34,796] Trial 15 finished with value: 5726.788302371912 and parameters: {'min_frequency': 0.16973355918529887, 'learning_rate': 0.00395589684037638, 'n_estimators': 986, 'max_depth': 8, 'max_leaves': 77, 'min_child_weight': 2, 'reg_alpha': 0.005967578926037054, 'reg_lambda': 0.5575254986897987}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:36,359] Trial 16 finished with value: 6641.722882789031 and parameters: {'min_frequency': 0.2669421392728392, 'learning_rate': 0.08054373462948097, 'n_estimators': 338, 'max_depth': 5, 'max_leaves': 80, 'min_child_weight': 2, 'reg_alpha': 0.7437473540348526, 'reg_lambda': 0.44994987646260187}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:41,824] Trial 17 finished with value: 6317.668767748274 and parameters: {'min_frequency': 0.0996974448189078, 'learning_rate': 0.08763597346224061, 'n_estimators': 898, 'max_depth': 8, 'max_leaves': 38, 'min_child_weight': 2, 'reg_alpha': 0.37007959829076015, 'reg_lambda': 0.6042231013694808}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:47,217] Trial 18 finished with value: 6406.686771978523 and parameters: {'min_frequency': 0.09058465380330731, 'learning_rate': 0.07314602158112969, 'n_estimators': 659, 'max_depth': 8, 'max_leaves': 68, 'min_child_weight': 2, 'reg_alpha': 0.5402630578666935, 'reg_lambda': 0.3848663811972053}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:52,936] Trial 19 finished with value: 7630.8168954683715 and parameters: {'min_frequency': 0.23977006109459098, 'learning_rate': 0.09033386439003144, 'n_estimators': 877, 'max_depth': 9, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.3982285165958367, 'reg_lambda': 0.8417652166380098}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:57,146] Trial 20 finished with value: 9595.106051232373 and parameters: {'min_frequency': 0.37861434588972287, 'learning_rate': 0.07166768803459687, 'n_estimators': 994, 'max_depth': 6, 'max_leaves': 74, 'min_child_weight': 2, 'reg_alpha': 0.3381121448805884, 'reg_lambda': 0.6689222844016085}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:07,685] Trial 21 finished with value: 2151.522839208789 and parameters: {'min_frequency': 0.009487226914815218, 'learning_rate': 0.09225535043635506, 'n_estimators': 847, 'max_depth': 9, 'max_leaves': 91, 'min_child_weight': 5, 'reg_alpha': 0.4989584483998449, 'reg_lambda': 0.9082842679263758}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:17,274] Trial 22 finished with value: 2170.2192123677924 and parameters: {'min_frequency': 0.0022652556785879296, 'learning_rate': 0.07939217498900059, 'n_estimators': 744, 'max_depth': 9, 'max_leaves': 91, 'min_child_weight': 4, 'reg_alpha': 0.4559120844903792, 'reg_lambda': 0.7692581990480446}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:23,726] Trial 23 finished with value: 6752.607305997841 and parameters: {'min_frequency': 0.10668584756384228, 'learning_rate': 0.09999680436133582, 'n_estimators': 898, 'max_depth': 8, 'max_leaves': 72, 'min_child_weight': 3, 'reg_alpha': 0.3684145588267173, 'reg_lambda': 0.8921400104804674}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:29,775] Trial 24 finished with value: 6716.7113037109375 and parameters: {'min_frequency': 0.14336394845200642, 'learning_rate': 0.08346534510690193, 'n_estimators': 794, 'max_depth': 9, 'max_leaves': 99, 'min_child_weight': 5, 'reg_alpha': 0.4944130829323471, 'reg_lambda': 0.9954112384757989}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:38,570] Trial 25 finished with value: 1951.8277633524388 and parameters: {'min_frequency': 0.07635478834392678, 'learning_rate': 0.09032442930563103, 'n_estimators': 913, 'max_depth': 8, 'max_leaves': 83, 'min_child_weight': 3, 'reg_alpha': 0.5590535826737515, 'reg_lambda': 0.6940799730661463}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:26:51,549] Trial 26 finished with value: 7698.152440599511 and parameters: {'min_frequency': 0.2732263050685856, 'learning_rate': 0.0922509057180985, 'n_estimators': 902, 'max_depth': 8, 'max_leaves': 82, 'min_child_weight': 3, 'reg_alpha': 0.727393307583318, 'reg_lambda': 0.688461577672377}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:04,976] Trial 27 finished with value: 2016.7320866298294 and parameters: {'min_frequency': 0.07716820944890182, 'learning_rate': 0.07684765352404443, 'n_estimators': 1000, 'max_depth': 7, 'max_leaves': 64, 'min_child_weight': 2, 'reg_alpha': 0.5468161355332433, 'reg_lambda': 0.5658751951792086}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:09,694] Trial 28 finished with value: 7123.846192058161 and parameters: {'min_frequency': 0.2097395568897438, 'learning_rate': 0.09219778809987268, 'n_estimators': 681, 'max_depth': 6, 'max_leaves': 46, 'min_child_weight': 2, 'reg_alpha': 0.40218838455170747, 'reg_lambda': 0.694611196031858}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:13,994] Trial 29 finished with value: 6113.721425768212 and parameters: {'min_frequency': 0.13599260137771899, 'learning_rate': 0.06541762109912105, 'n_estimators': 599, 'max_depth': 7, 'max_leaves': 55, 'min_child_weight': 3, 'reg_alpha': 0.42890629128150703, 'reg_lambda': 0.859420356034406}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:22,057] Trial 30 finished with value: 1987.7507200355683 and parameters: {'min_frequency': 0.0706634467175034, 'learning_rate': 0.07168499308197432, 'n_estimators': 915, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 1, 'reg_alpha': 0.5353747357065575, 'reg_lambda': 0.9287062763452252}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:30,565] Trial 31 finished with value: 1981.618513160777 and parameters: {'min_frequency': 0.06775685577857174, 'learning_rate': 0.07307303457849289, 'n_estimators': 929, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 1, 'reg_alpha': 0.5345238968215354, 'reg_lambda': 0.9289253897002412}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:38,385] Trial 32 finished with value: 5444.596490144411 and parameters: {'min_frequency': 0.08416472170607733, 'learning_rate': 0.07089983736470647, 'n_estimators': 910, 'max_depth': 7, 'max_leaves': 90, 'min_child_weight': 1, 'reg_alpha': 0.5434606089108242, 'reg_lambda': 0.9280173459134533}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:45,129] Trial 33 finished with value: 6616.8968588163125 and parameters: {'min_frequency': 0.15232840637535372, 'learning_rate': 0.08617841795325297, 'n_estimators': 831, 'max_depth': 8, 'max_leaves': 93, 'min_child_weight': 1, 'reg_alpha': 0.6191839391730279, 'reg_lambda': 0.9578591592847099}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:52,362] Trial 34 finished with value: 1980.5381110360688 and parameters: {'min_frequency': 0.06761634774174481, 'learning_rate': 0.06829630848947744, 'n_estimators': 779, 'max_depth': 10, 'max_leaves': 72, 'min_child_weight': 1, 'reg_alpha': 0.5365609639643151, 'reg_lambda': 0.8742412980609915}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:58,057] Trial 35 finished with value: 6379.291342232352 and parameters: {'min_frequency': 0.16363515592960237, 'learning_rate': 0.06682603010619002, 'n_estimators': 776, 'max_depth': 10, 'max_leaves': 71, 'min_child_weight': 1, 'reg_alpha': 0.4789667474411971, 'reg_lambda': 0.8477998270111955}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:05,647] Trial 36 finished with value: 2053.351215194478 and parameters: {'min_frequency': 0.07527259394284794, 'learning_rate': 0.05698579780216279, 'n_estimators': 855, 'max_depth': 10, 'max_leaves': 61, 'min_child_weight': 1, 'reg_alpha': 0.6937668363051048, 'reg_lambda': 0.8824046278364724}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:10,691] Trial 37 finished with value: 7327.105006708163 and parameters: {'min_frequency': 0.23247560619644547, 'learning_rate': 0.0780670288620528, 'n_estimators': 714, 'max_depth': 9, 'max_leaves': 77, 'min_child_weight': 1, 'reg_alpha': 0.5755827791298328, 'reg_lambda': 0.8092286106299579}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:12,832] Trial 38 finished with value: 6894.152823067476 and parameters: {'min_frequency': 0.3173974428464182, 'learning_rate': 0.09541461493663626, 'n_estimators': 246, 'max_depth': 10, 'max_leaves': 85, 'min_child_weight': 2, 'reg_alpha': 0.6369605724247737, 'reg_lambda': 0.9995769958634034}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:17,183] Trial 39 finished with value: 2079.5616513750106 and parameters: {'min_frequency': 0.04850481474884455, 'learning_rate': 0.08592244820379323, 'n_estimators': 522, 'max_depth': 9, 'max_leaves': 57, 'min_child_weight': 4, 'reg_alpha': 0.65913309470509, 'reg_lambda': 0.7483551430621875}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:23,243] Trial 40 finished with value: 6652.474456827854 and parameters: {'min_frequency': 0.13155861406098457, 'learning_rate': 0.09454489060341995, 'n_estimators': 810, 'max_depth': 9, 'max_leaves': 77, 'min_child_weight': 1, 'reg_alpha': 0.7760631695435911, 'reg_lambda': 0.8366310628742767}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:32,124] Trial 41 finished with value: 1993.8648699568175 and parameters: {'min_frequency': 0.061882306115692474, 'learning_rate': 0.07369797400450741, 'n_estimators': 928, 'max_depth': 7, 'max_leaves': 94, 'min_child_weight': 1, 'reg_alpha': 0.5281903981068817, 'reg_lambda': 0.9309416834705204}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:41,915] Trial 42 finished with value: 2028.245370617855 and parameters: {'min_frequency': 0.05880274052932534, 'learning_rate': 0.08158664650672792, 'n_estimators': 861, 'max_depth': 8, 'max_leaves': 86, 'min_child_weight': 1, 'reg_alpha': 0.575741034657216, 'reg_lambda': 0.916035407254763}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:50,609] Trial 43 finished with value: 6609.840556288593 and parameters: {'min_frequency': 0.17926226048963725, 'learning_rate': 0.06775877650580238, 'n_estimators': 942, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 1, 'reg_alpha': 0.5168228697053815, 'reg_lambda': 0.949193800978987}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:58,480] Trial 44 finished with value: 6344.549157014039 and parameters: {'min_frequency': 0.10548737726206583, 'learning_rate': 0.06128597809034258, 'n_estimators': 926, 'max_depth': 8, 'max_leaves': 66, 'min_child_weight': 1, 'reg_alpha': 0.4482515812234238, 'reg_lambda': 0.8788398686733475}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:11,043] Trial 45 finished with value: 2197.6040594816527 and parameters: {'min_frequency': 0.000436676809238706, 'learning_rate': 0.08923295921968599, 'n_estimators': 755, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 2, 'reg_alpha': 0.5896908719350288, 'reg_lambda': 0.7992902278626857}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:19,402] Trial 46 finished with value: 2024.7219604981121 and parameters: {'min_frequency': 0.04015931783596217, 'learning_rate': 0.05435580672377532, 'n_estimators': 829, 'max_depth': 9, 'max_leaves': 81, 'min_child_weight': 1, 'reg_alpha': 0.49196448685204974, 'reg_lambda': 0.9584794520623106}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:26,234] Trial 47 finished with value: 6286.021649960364 and parameters: {'min_frequency': 0.12812690452045666, 'learning_rate': 0.06120062201792585, 'n_estimators': 955, 'max_depth': 6, 'max_leaves': 100, 'min_child_weight': 1, 'reg_alpha': 0.4425090736667596, 'reg_lambda': 0.9059972947298723}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:27,179] Trial 48 finished with value: 3044.656306553269 and parameters: {'min_frequency': 0.04696158407280705, 'learning_rate': 0.09586460933984163, 'n_estimators': 67, 'max_depth': 7, 'max_leaves': 37, 'min_child_weight': 2, 'reg_alpha': 0.6541959075220233, 'reg_lambda': 0.7492156683743074}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:30,758] Trial 49 finished with value: 5939.746433069614 and parameters: {'min_frequency': 0.1898536821803897, 'learning_rate': 0.08265171126394048, 'n_estimators': 656, 'max_depth': 5, 'max_leaves': 70, 'min_child_weight': 3, 'reg_alpha': 0.5641775239038888, 'reg_lambda': 0.9993200258497689}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:33,816] Trial 50 finished with value: 5788.450802404508 and parameters: {'min_frequency': 0.11202481434223271, 'learning_rate': 0.07575219257584644, 'n_estimators': 443, 'max_depth': 8, 'max_leaves': 24, 'min_child_weight': 1, 'reg_alpha': 0.5141631526272215, 'reg_lambda': 0.8266626331588254}. Best is trial 25 with value: 1951.8277633524388.\n"]}],"source":["# Seteando semilla de optuna\n","optuna_seed = 0\n","\n","# Sampler\n","sampler = optuna.samplers.TPESampler(seed=optuna_seed)\n","\n","# Generando el estudio de hiperparámetros\n","study = optuna.create_study(direction='minimize', sampler=sampler)\n","study.optimize(objective, timeout=300)  # 5 min de entrenamiento"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de trials hechos: 51 \n","Mejor MAE obtenido: 1951.8277633524388 \n","Mejores hiperparámetros: {'min_frequency': 0.07635478834392678, 'learning_rate': 0.09032442930563103, 'n_estimators': 913, 'max_depth': 8, 'max_leaves': 83, 'min_child_weight': 3, 'reg_alpha': 0.5590535826737515, 'reg_lambda': 0.6940799730661463}\n"]}],"source":["# Obteniendo la cantidad de trials, el mejor MAE y los mejores hiperparámetros\n","n_trails = len(study.trials)\n","best_mae = study.best_value\n","best_hp = study.best_params\n","print(f\"Cantidad de trials hechos: {n_trails} \\nMejor MAE obtenido: {best_mae} \\nMejores hiperparámetros: {best_hp}\")"]},{"cell_type":"markdown","metadata":{},"source":["> El MAE mejoró considerablemente, lo que indica que el modelo es mucho mejor que el anterior. Esto se debe a que se optimizaron los hiperparámetros, complejizando el modelo y la interrelación de los parámetros con el entrenamiento, adecuandolo a los datos. Así, se tiene que el modelo es mucho mejor que el anterior, ya que se optimizaron los hiperparámetros para que se ajusten mejor a los datos."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["['models/best_xgb_model1.pkl']"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Obteniendo el mejor modelo\n","cat_pipe_best = Pipeline([\n","    ('Encoder', OneHotEncoder(min_frequency=best_hp['min_frequency'], sparse_output=False))\n","])\n","\n","ctrans_best = ColumnTransformer(\n","        transformers=[\n","            (\"Categorico\", cat_pipe_best, cat_cols),\n","            (\"Numerico\", num_pipe, num_cols),\n","        ],\n","        remainder=\"passthrough\",\n","        verbose_feature_names_out=False\n",")\n","ctrans_best.set_output(transform='pandas')\n","\n","# Mejor pipeline\n","pipe_train_best = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans_best),\n","    (\"Classifier\", xgb.XGBRegressor(learning_rate=best_hp['learning_rate'],\n","                                    n_estimators=best_hp['n_estimators'],\n","                                    max_depth=best_hp['max_depth'],\n","                                    max_leaves=best_hp['max_leaves'],\n","                                    min_child_weight=best_hp['min_child_weight'],\n","                                    reg_alpha=best_hp['reg_alpha'],\n","                                    reg_lambda=best_hp['reg_lambda']))\n","])\n","\n","# Entrenando el mejor pipeline\n","model_best = pipe_train_best.fit(X_train, y_train)\n","\n","# Guardando el mejor modelo\n","joblib.dump(model_best, \"models/best_xgb_model1.pkl\")"]},{"cell_type":"markdown","metadata":{"cell_id":"5195ccfc37e044ad9453f6eb2754f631","deepnote_cell_type":"markdown"},"source":["## 1.4 Optimización de Hiperparámetros con Optuna y Prunners (1.7)\n","\n","<p align=\"center\">\n","  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n","</p>\n","\n","Después de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en sí mismo. Después de leer un par de post de personas de dudosa reputación en la *deepweb*, usted llega a la conclusión que puede cumplir este objetivo mediante la implementación de **Prunning**.\n","\n","Vuelva a optimizar los mismos hiperparámetros que la sección pasada, pero esta vez utilizando **Prunning** en la optimización. En particular, usted debe:\n","\n","- Responder: ¿Qué es prunning? ¿De qué forma debería impactar en el entrenamiento?\n","- Utilizar `optuna.integration.XGBoostPruningCallback` como método de **Prunning**\n","- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n","- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n","- Guardar su modelo en un archivo .pkl\n","\n","Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n","\n","```\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","```\n","\n","De implementar la opción anterior, pueden especificar `show_progress_bar = True` en el método `optimize` para *más sabor*.\n","\n","Hint: Si quieren especificar parámetros del método .fit() del modelo a través del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n","\n","Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementación"]},{"cell_type":"markdown","metadata":{},"source":["> Prunning o \"poda\" es una forma de simplificar o reducir la estructura de un modelo con el fin de mejorar su rendimiento. Esto se hace eliminando nodos o ramas del modelo, lo que ayuda a reducir el overfitting y la complejidad del modelo. Al hacer esto, se espera que la capacidad de generalización frente a datos nuevos sea aun mayor y, por otro lado, mejorar la eficiencia computacional del modelo al hacerlo \"menos costoso\" de entrenar."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Creando la optimización con Optuna\n","\n","def objective2(trial):\n","    \"\"\"\n","    Función objetivo para optimizar los hiperparámetros del modelo. Utiliza la libreria Optuna y método Prunning.\n","\n","    Parameters\n","    ----------\n","    trial : optuna.trial._trial.Trial\n","        Objeto de la clase Trial de Optuna.\n","\n","    Returns\n","    -------\n","    mae_opt : float\n","        Error absoluto medio del modelo optimizado. Es el valor que se intenta minimizar.\n","    \"\"\"\n","    # Agregando valores a probar\n","    min_frequency = trial.suggest_float('min_frequency', 0, 1)\n","    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1)\n","    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n","    max_depth = trial.suggest_int('max_depth', 3, 10)\n","    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n","    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n","    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n","    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n","\n","    # Re-editando el OneHotEncoder de ColumnTransformer\n","    cat_pipe = Pipeline([\n","        ('Encoder', OneHotEncoder(min_frequency=min_frequency, sparse_output=False))\n","    ])\n","\n","    ctrans = ColumnTransformer(\n","            transformers=[\n","                (\"Categorico\", cat_pipe, cat_cols),\n","                (\"Numerico\", num_pipe, num_cols),\n","            ],\n","            remainder=\"passthrough\",\n","            verbose_feature_names_out=False\n","    )\n","    ctrans.set_output(transform='pandas')\n","\n","    # Definiendo el prunning\n","    pruning_callback = optuna.integration.XGBoostPruningCallback(\n","        trial, observation_key=\"validation_1-mae\"\n","    )\n","\n","    # Mejor de los 3 pipelines anteriores: pipeline 2\n","    pipe_train2 = Pipeline([\n","        (\"Date extraction\", FunctionTransformer(extract_date)),\n","        (\"Scaling\", ctrans),\n","        (\"Classifier\", xgb.XGBRegressor(learning_rate=learning_rate,\n","                                        n_estimators=n_estimators,\n","                                        max_depth=max_depth,\n","                                        max_leaves=max_leaves,\n","                                        min_child_weight=min_child_weight,\n","                                        reg_alpha=reg_alpha,\n","                                        reg_lambda=reg_lambda,\n","                                        eval_metric='mae',\n","                                        early_stopping_rounds=10,\n","                                        callbacks=[pruning_callback]))\n","    ])\n","\n","    # Paso necesario\n","    pipe_dumb = Pipeline([\n","        (\"Date extraction\", FunctionTransformer(extract_date)),\n","        (\"Scaling\", ctrans)\n","    ])\n","    step = pipe_dumb.fit(X_train, y_train)\n","    X_train2 = step.transform(X_train)\n","    X_val2 = step.transform(X_val)\n","\n","    # Entrenando el pipeline\n","    model_opt = pipe_train2.fit(X_train,\n","                                y_train,\n","                                Classifier__eval_set=[(X_train2, y_train), (X_val2, y_val)],\n","                                Classifier__verbose=False)\n","\n","    # Prediciendo\n","    y_pred_opt = model_opt.predict(X_val)\n","\n","    # Obteniendo el MAE\n","    mae_opt = mean_absolute_error(y_val, y_pred_opt)\n","\n","    return mae_opt"]},{"cell_type":"code","execution_count":16,"metadata":{"cell_id":"eeaa967cd8f6426d8c54f276c17dce79","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["   0%|          | 00:00/05:00"]},{"name":"stderr","output_type":"stream","text":["Best trial: 12. Best value: 2029.99:  100%|██████████| 05:00/05:00\n"]}],"source":["# Quitando los prints de prunning\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","# Generando el estudio de hiperparámetros\n","study2 = optuna.create_study(direction='minimize', sampler=sampler)\n","study2.optimize(objective2, timeout=300, show_progress_bar=True)  # 5 min de entrenamiento"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de trials hechos: 129 \n","Mejor MAE obtenido: 2029.9910766438584 \n","Mejores hiperparámetros: {'min_frequency': 0.03402343044784076, 'learning_rate': 0.09943651925920696, 'n_estimators': 415, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 1, 'reg_alpha': 0.2104797919643507, 'reg_lambda': 0.03098980392770021}\n"]}],"source":["# Obteniendo la cantidad de trials, el mejor MAE y los mejores hiperparámetros\n","n_trails2 = len(study2.trials)\n","best_mae2 = study2.best_value\n","best_hp2 = study2.best_params\n","print(f\"Cantidad de trials hechos: {n_trails2} \\nMejor MAE obtenido: {best_mae2} \\nMejores hiperparámetros: {best_hp2}\")"]},{"cell_type":"markdown","metadata":{},"source":["> El MAE empeoró levemente en comparación al modelo optimizado anteriormente, ya que aumentó. Mientras que se espera que al quitar pruebas se evite el overfitting y así tener una mejora del modelo, la variabilidad de los hiperparámetros de forma aleatoria conlleva a que se tenga también mayor variabilidad al momento de obtener su MAE. Al ir quitando pruebas, se van generando cada vez más trials, lo que aumenta la variabilidad de los parámetors, abriendo más posibilidades de resultados, lo que puede mejorar o empeorar el modelo. Para esta corrida, se empeoró."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["['models/best_xgb_model2.pkl']"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Obteniendo el mejor modelo\n","cat_pipe_best2 = Pipeline([\n","    ('Encoder', OneHotEncoder(min_frequency=best_hp2['min_frequency'], sparse_output=False))\n","])\n","\n","ctrans_best2 = ColumnTransformer(\n","        transformers=[\n","            (\"Categorico\", cat_pipe_best2, cat_cols),\n","            (\"Numerico\", num_pipe, num_cols),\n","        ],\n","        remainder=\"passthrough\",\n","        verbose_feature_names_out=False\n",")\n","ctrans_best2.set_output(transform='pandas')\n","\n","# Mejor pipeline\n","pipe_train_best2 = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans_best2),\n","    (\"Classifier\", xgb.XGBRegressor(learning_rate=best_hp2['learning_rate'],\n","                                    n_estimators=best_hp2['n_estimators'],\n","                                    max_depth=best_hp2['max_depth'],\n","                                    max_leaves=best_hp2['max_leaves'],\n","                                    min_child_weight=best_hp2['min_child_weight'],\n","                                    reg_alpha=best_hp2['reg_alpha'],\n","                                    reg_lambda=best_hp2['reg_lambda']))\n","])\n","\n","# Entrenando el mejor pipeline\n","model_best2 = pipe_train_best2.fit(X_train, y_train)\n","\n","# Guardando el mejor modelo\n","joblib.dump(model_best2, \"models/best_xgb_model2.pkl\")"]},{"cell_type":"markdown","metadata":{"cell_id":"8a081778cc704fc6bed05393a5419327","deepnote_cell_type":"markdown"},"source":["## 1.5 Visualizaciones (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n","</p>\n","\n","\n","Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n","\n","A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n","\n","- Gráfico de historial de optimización\n","- Gráfico de coordenadas paralelas\n","- Gráfico de importancia de hiperparámetros\n","\n","Comente sus resultados: ¿Desde qué *trial* se empiezan a observar mejoras notables en sus resultados? ¿Qué tendencias puede observar a partir del gráfico de coordenadas paralelas? ¿Cuáles son los hiperparámetros con mayor importancia para la optimización de su modelo?"]},{"cell_type":"code","execution_count":19,"metadata":{"cell_id":"0e706dc9a8d946eda7a9eb1f0463c6d7","deepnote_cell_type":"code"},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"mode":"markers","name":"MAE","type":"scatter","x":[0,1,2,3,4,9,10,11,12,15,20,27,31,37,41,42,55,102,105,120,122,125],"y":[6341.053950514749,8296.199255582966,8634.110806596294,6274.878778149512,8343.942307190839,5687.3579463373035,2079.7774565305826,2277.847836992292,2029.9910766438584,5724.292463845022,5710.082753567256,5633.374085369033,5682.727604579543,5681.222166827906,5679.493011841309,2030.435602287425,2042.7986048455232,5678.356557441171,5673.777153717978,5669.160293803196,5674.0098904659335,2115.2486386471023]},{"mode":"lines","name":"Best Value","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128],"y":[6341.053950514749,6341.053950514749,6341.053950514749,6274.878778149512,6274.878778149512,6274.878778149512,6274.878778149512,6274.878778149512,6274.878778149512,5687.3579463373035,2079.7774565305826,2079.7774565305826,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584]},{"marker":{"color":"#cccccc"},"mode":"markers","name":"Infeasible Trial","showlegend":false,"type":"scatter","x":[],"y":[]}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Optimization History Plot"},"xaxis":{"title":{"text":"Trial"}},"yaxis":{"title":{"text":"MAE"}}}}},"metadata":{},"output_type":"display_data"}],"source":["# Obteniendo las herramientas gráficas\n","from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_param_importances\n","\n","# Gráfico de historial de optimización\n","plot_optimization_history(study2, target_name=\"MAE\")"]},{"cell_type":"markdown","metadata":{},"source":["> Comentario XD"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"dimensions":[{"label":"MAE","range":[2029.9910766438584,8634.110806596294],"values":[6341.053950514749,8296.199255582966,8634.110806596294,6274.878778149512,8343.942307190839,5687.3579463373035,2079.7774565305826,2277.847836992292,2029.9910766438584,5724.292463845022,5710.082753567256,5633.374085369033,5682.727604579543,5681.222166827906,5679.493011841309,2030.435602287425,2042.7986048455232,5678.356557441171,5673.777153717978,5669.160293803196,5674.0098904659335,2115.2486386471023]},{"label":"learning_rate","range":[0.002990647072561862,0.09993220213590467],"values":[0.04201203645695233,0.0930003235600452,0.002990647072561862,0.058039576107365855,0.030446258134658236,0.06194039686410058,0.09359482400048519,0.09983177137679547,0.09943651925920696,0.09825950518836689,0.08824502651120517,0.09953709610997145,0.09960786067816955,0.09466906234372463,0.09626623251950868,0.09555890961631497,0.09951612393767433,0.09549350447836313,0.09780880623083119,0.09993220213590467,0.09985001454677227,0.09801466378525917]},{"label":"max_depth","range":[3,10],"values":[8,8,3,7,6,9,10,10,10,9,9,10,10,8,8,10,10,7,7,7,7,7]},{"label":"max_leaves","range":[13,100],"values":[57,13,68,22,88,81,100,100,100,77,67,46,48,93,92,100,96,91,98,83,83,86]},{"label":"min_child_weight","range":[1,5],"values":[2,4,2,5,3,3,1,1,1,1,4,2,2,2,2,4,1,4,1,3,3,3]},{"label":"min_frequency","range":[0.003905887857990814,0.6994792753175043],"values":[0.317983179393976,0.5759464955561793,0.5865129348100832,0.24875314351995803,0.6994792753175043,0.16249293467637482,0.03696509764442346,0.003905887857990814,0.03402343044784076,0.17915005741270484,0.09600766176834163,0.16833192680088038,0.08890841085194288,0.12655259987076176,0.14180755212732163,0.05499276882128483,0.05781127332453817,0.15646913911686364,0.11267377687323496,0.1287130670290348,0.16486596042455884,0.05734626081402613]},{"label":"n_estimators","range":[54,838],"values":[111,352,838,613,823,167,360,359,415,463,54,318,310,302,309,355,408,95,360,296,297,230]},{"label":"reg_alpha","range":[0.13284282828205216,0.8817353618548528],"values":[0.5232480534666997,0.2894060929472011,0.7351940221225949,0.44712537861762736,0.8817353618548528,0.40718329722599966,0.2666628387780338,0.24926003344538708,0.2104797919643507,0.3328337593283573,0.5961096743333528,0.2999158948305251,0.29696003008684224,0.25399355152191094,0.22904515996146946,0.13284282828205216,0.15721122349406685,0.5493405938079492,0.2030493915569775,0.27777120648286013,0.2726707939146492,0.28892602143010715]},{"label":"reg_lambda","range":[0.006592953321621478,0.9621885451174382],"values":[0.09394051075844168,0.18319136200711683,0.9621885451174382,0.8464086724711278,0.6925315900777659,0.06916699545513805,0.025735853373902648,0.006592953321621478,0.03098980392770021,0.38319223771168814,0.13518471690938821,0.16476970353052567,0.14338283639771165,0.19028429387991025,0.18574600895069301,0.0488955698251497,0.15012371856966114,0.11371446648391995,0.047107789081093435,0.17908225894256152,0.22541188950185642,0.1703222805856767]}],"labelangle":30,"labelside":"bottom","line":{"color":[6341.053950514749,8296.199255582966,8634.110806596294,6274.878778149512,8343.942307190839,5687.3579463373035,2079.7774565305826,2277.847836992292,2029.9910766438584,5724.292463845022,5710.082753567256,5633.374085369033,5682.727604579543,5681.222166827906,5679.493011841309,2030.435602287425,2042.7986048455232,5678.356557441171,5673.777153717978,5669.160293803196,5674.0098904659335,2115.2486386471023],"colorbar":{"title":{"text":"MAE"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"reversescale":true,"showscale":true},"type":"parcoords"}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Parallel Coordinate Plot"}}}},"metadata":{},"output_type":"display_data"}],"source":["# Gráfico de coordenadas paralelas\n","plot_parallel_coordinate(study2, target_name=\"MAE\")"]},{"cell_type":"markdown","metadata":{},"source":["> Comentario XD"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"cliponaxis":false,"hovertemplate":["min_child_weight (IntDistribution): 0.011093209321839948<extra></extra>","max_depth (IntDistribution): 0.01574958216139927<extra></extra>","n_estimators (IntDistribution): 0.01648848204120843<extra></extra>","learning_rate (FloatDistribution): 0.01841056138235843<extra></extra>","reg_lambda (FloatDistribution): 0.027948532410473282<extra></extra>","reg_alpha (FloatDistribution): 0.0362088735711912<extra></extra>","max_leaves (IntDistribution): 0.03898203101519217<extra></extra>","min_frequency (FloatDistribution): 0.8351187280963374<extra></extra>"],"name":"MAE","orientation":"h","text":["0.01","0.02","0.02","0.02","0.03","0.04","0.04","0.84"],"textposition":"outside","type":"bar","x":[0.011093209321839948,0.01574958216139927,0.01648848204120843,0.01841056138235843,0.027948532410473282,0.0362088735711912,0.03898203101519217,0.8351187280963374],"y":["min_child_weight","max_depth","n_estimators","learning_rate","reg_lambda","reg_alpha","max_leaves","min_frequency"]}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Hyperparameter Importance"}},"yaxis":{"title":{"text":"Hyperparameter"}}}}},"metadata":{},"output_type":"display_data"}],"source":["# Gráfico de importancia de hiperparámetros\n","plot_param_importances(study2, target_name=\"MAE\")"]},{"cell_type":"markdown","metadata":{},"source":["> Comentario XD"]},{"cell_type":"markdown","metadata":{"cell_id":"ac8a20f445d045a3becf1a518d410a7d","deepnote_cell_type":"markdown"},"source":["## 1.6 Síntesis de resultados (0.3)\n","\n","Finalmente, genere una tabla resumen del MAE obtenido en los 5 modelos entrenados (desde Baseline hasta XGBoost con Constraints, Optuna y Prunning) y compare sus resultados. ¿Qué modelo obtiene el mejor rendimiento? \n","\n","Por último, cargue el mejor modelo, prediga sobre el conjunto de test y reporte su MAE. ¿Existen diferencias con respecto a las métricas obtenidas en el conjunto de validación? ¿Porqué puede ocurrir esto?"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Modelos</th>\n","      <th>MAE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Baseline</td>\n","      <td>13308.134751</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>XGBoost</td>\n","      <td>2500.322145</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>XGBoost Constraints</td>\n","      <td>2707.911759</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>XGBoost Optuna</td>\n","      <td>1951.827763</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>XGBoost Prunning</td>\n","      <td>2029.991077</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Modelos           MAE\n","0             Baseline  13308.134751\n","1              XGBoost   2500.322145\n","2  XGBoost Constraints   2707.911759\n","3       XGBoost Optuna   1951.827763\n","4     XGBoost Prunning   2029.991077"]},"metadata":{},"output_type":"display_data"}],"source":["from IPython.display import display\n","\n","# Generando tabla resumen\n","summary = {\"Modelos\": [\"Baseline\", \"XGBoost\", \"XGBoost Constraints\", \"XGBoost Optuna\", \"XGBoost Prunning\"],\n","           \"MAE\": [mae1, mae2, mae3, best_mae, best_mae2]}\n","\n","df_sum = pd.DataFrame(summary)\n","display(df_sum)"]},{"cell_type":"markdown","metadata":{},"source":["> Comentario XD"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE del mejor modelo en el conjunto de prueba: 2000.6314546949002\n"]}],"source":["# Mejor modelo: XGBoost Optuna\n","best_model = joblib.load(\"models/best_xgb_model1.pkl\")\n","\n","# Prediciendo en test\n","best_y_pred = best_model.predict(X_test)\n","\n","# Obteniendo su MAE\n","best_mae_final = mean_absolute_error(y_test, best_y_pred)\n","print(f\"MAE del mejor modelo en el conjunto de prueba: {best_mae_final}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"5c4654d12037494fbd385b4dc6bd1059","deepnote_cell_type":"markdown"},"source":["# Conclusión\n","Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n","</p>"]},{"cell_type":"markdown","metadata":{"cell_id":"5025de06759f4903a26916c80323bf25","deepnote_cell_type":"markdown"},"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"f63d38450a6b464c9bb6385cf11db4d9","deepnote_persisted_session":{"createdAt":"2023-11-09T16:18:30.203Z"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
