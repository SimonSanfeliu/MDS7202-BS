{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b5c0d2440b3e4995a794ded565213150","deepnote_cell_type":"markdown"},"source":["<h1><center>Laboratorio 9: Optimizaci칩n de modelos 游눮</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>"]},{"cell_type":"markdown","metadata":{"cell_id":"bfb94b9656f145ad83e81b75d218cb70","deepnote_cell_type":"markdown"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Ignacio Meza, Gabriel Iturra\n","- Auxiliar: Sebasti치n Tinoco\n","- Ayudante: Arturo Lazcano, Angelo Mu침oz"]},{"cell_type":"markdown","metadata":{"cell_id":"b1b537fdd27c43909a49d3476ce64d91","deepnote_cell_type":"markdown"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n","\n","- Nombre de alumno 1: Nicol치s Becerra\n","- Nombre de alumno 2: Sim칩n Sanfeli칰\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b7dbdd30ab544cb8a8afe00648a586ae","deepnote_cell_type":"markdown"},"source":["## Temas a tratar\n","\n","- Predicci칩n de demanda usando `xgboost`\n","- B칰squeda del modelo 칩ptimo de clasificaci칩n usando `optuna`\n","- Uso de pipelines.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer material del curso que estimen conveniente.\n","\n","### Objetivos principales del laboratorio\n","\n","- Optimizar modelos usando `optuna`\n","- Recurrir a t칠cnicas de *prunning*\n","- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n","- Fijar un pipeline con un modelo base que luego se ir치 optimizando.\n","\n","El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."]},{"cell_type":"markdown","metadata":{"cell_id":"f38c8342f5164aa992a97488dd5590bf","deepnote_cell_type":"markdown"},"source":["### **Link de repositorio de GitHub:** https://github.com/SimonSanfeliu/MDS7202-BS/tree/L9"]},{"cell_type":"markdown","metadata":{"cell_id":"f1c73babb7f74af588a4fa6ae14829e0","deepnote_cell_type":"markdown"},"source":["# Importamos librerias 칰tiles"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"51afe4d2df42442b9e5402ffece60ead","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4957,"execution_start":1699544354044,"source_hash":null},"outputs":[],"source":["!pip install -qq xgboost optuna"]},{"cell_type":"markdown","metadata":{"cell_id":"44d227389a734ac59189c5e0005bc68a","deepnote_cell_type":"markdown"},"source":["# 1. El emprendimiento de Fiu\n","\n","Tras liderar de manera exitosa la implementaci칩n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp칩reo **Fiu** se anima y decide levantar su propio negocio de consultor칤a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterizaci칩n de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n","\n","Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n","\n","Para comenzar, cargue el dataset se침alado y visualice a trav칠s de un `.head` los atributos que posee el dataset.\n","\n","<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe침o en el proyecto de caracterizaci칩n de datos</p></i>\n","<p align=\"center\">\n","  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n","</p>"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"2f9c82d204b14515ad27ae07e0b77702","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":92,"execution_start":1699544359006,"source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\sanfe\\AppData\\Local\\Temp\\ipykernel_3380\\3184305967.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df['date'] = pd.to_datetime(df['date'])\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>city</th>\n","      <th>lat</th>\n","      <th>long</th>\n","      <th>pop</th>\n","      <th>shop</th>\n","      <th>brand</th>\n","      <th>container</th>\n","      <th>capacity</th>\n","      <th>price</th>\n","      <th>quantity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>0.96</td>\n","      <td>13280</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>plastic</td>\n","      <td>1.5lt</td>\n","      <td>2.86</td>\n","      <td>6727</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>kinder-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.87</td>\n","      <td>9848</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>glass</td>\n","      <td>500ml</td>\n","      <td>1.00</td>\n","      <td>20050</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2012-01-31</td>\n","      <td>Athens</td>\n","      <td>37.97945</td>\n","      <td>23.71622</td>\n","      <td>672130</td>\n","      <td>shop_1</td>\n","      <td>adult-cola</td>\n","      <td>can</td>\n","      <td>330ml</td>\n","      <td>0.39</td>\n","      <td>25696</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id       date    city       lat      long     pop    shop        brand  \\\n","0   0 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","1   1 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","2   2 2012-01-31  Athens  37.97945  23.71622  672130  shop_1  kinder-cola   \n","3   3 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","4   4 2012-01-31  Athens  37.97945  23.71622  672130  shop_1   adult-cola   \n","\n","  container capacity  price  quantity  \n","0     glass    500ml   0.96     13280  \n","1   plastic    1.5lt   2.86      6727  \n","2       can    330ml   0.87      9848  \n","3     glass    500ml   1.00     20050  \n","4       can    330ml   0.39     25696  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","\n","df = pd.read_csv('sales.csv')\n","df['date'] = pd.to_datetime(df['date'])\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"cell_id":"b50db6f2cb804932ae3f9e5748a6ea61","deepnote_cell_type":"markdown"},"source":["## 1.1 Generando un Baseline (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n","</p>\n","\n","Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag칤ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr치cticas* para entrenar correcta y debidamente su modelo. Despu칠s de un par de vueltas, llega a las siguientes tareas:\n","\n","1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n","2. Implemente un `FunctionTransformer` para extraer el d칤a, mes y a침o de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n","3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num칠ricos y categ칩ricos. Use `OneHotEncoder` para las variables categ칩ricas.\n","4. Guarde los pasos anteriores en un `Pipeline`, dejando como 칰ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n","5. Entrene el pipeline anterior y reporte la m칠trica `mean_absolute_error` sobre los datos de validaci칩n. 쮺칩mo se interpreta esta m칠trica para el contexto del negocio?\n","6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par치metros por default**. 쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el `DummyRegressor`?\n","7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Funci칩n para FunctionTransformer\n","def extract_date(df):\n","    \"\"\"\n","    Genera las columnas de a침o, mes y d칤a a partir de una columna de fechas.\n","\n","    Parameters\n","    ----------\n","    df : pd.DataFrame\n","        DataFrame con la columna de fechas.\n","\n","    Returns\n","    -------\n","    pd.DataFrame\n","        DataFrame con las columnas de a침o, mes y d칤a.\n","    \"\"\"\n","    # Revisando datos\n","    assert type(df) == pd.DataFrame\n","    assert \"date\" in df.columns\n","\n","    # Generando las columnas\n","    df = df.assign(\n","        year = [d.year for d in df[\"date\"].dt.date],\n","        month = [d.month for d in df[\"date\"].dt.date],\n","        day = [d.day for d in df[\"date\"].dt.date]\n","    )\n","\n","    # Transform치ndolas en categor칤as\n","    df = df.astype(\n","        {\n","            \"day\": \"category\",\n","            \"month\": \"category\",\n","            \"year\": \"category\"\n","        }\n","    )\n","\n","    return df\n","\n","# Funci칩n para transformaci칩n logar칤tmica\n","def to_log(df_s):\n","    \"\"\"\n","    Aplica una transformaci칩n logar칤timica a una serie de datos.\n","\n","    Parameters\n","    ----------\n","    df_s : pd.Series\n","        Serie de datos a transformar.\n","\n","    Returns\n","    -------\n","    pd.Series\n","        Serie de datos transformada. \n","    \"\"\"\n","    # Revisando datos\n","    assert type(df_s) == pd.DataFrame\n","\n","    # Transformando los datos de la serie a escala logar칤tmica\n","    df_s = df_s.apply(lambda x: np.log(x + 1))\n","    return df_s"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"1482c992d9494e5582b23dbd3431dbfd","deepnote_cell_type":"code"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"郊\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"郊쬪";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n","                  transformers=[(&#x27;Categorico&#x27;,\n","                                 Pipeline(steps=[(&#x27;Encoder&#x27;,\n","                                                  OneHotEncoder(sparse_output=False))]),\n","                                 [&#x27;date&#x27;, &#x27;city&#x27;, &#x27;shop&#x27;, &#x27;brand&#x27;, &#x27;container&#x27;,\n","                                  &#x27;capacity&#x27;, &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;]),\n","                                (&#x27;Numerico&#x27;,\n","                                 Pipeline(steps=[(&#x27;Logaritmic scaler&#x27;,\n","                                                  FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;,\n","                                                                      func=&lt;function to_log at 0x0000018E4D030B80&gt;)),\n","                                                 (&#x27;MinMax scaler&#x27;,\n","                                                  MinMaxScaler())]),\n","                                 [&#x27;lat&#x27;, &#x27;long&#x27;, &#x27;pop&#x27;, &#x27;price&#x27;])],\n","                  verbose_feature_names_out=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n","                  transformers=[(&#x27;Categorico&#x27;,\n","                                 Pipeline(steps=[(&#x27;Encoder&#x27;,\n","                                                  OneHotEncoder(sparse_output=False))]),\n","                                 [&#x27;date&#x27;, &#x27;city&#x27;, &#x27;shop&#x27;, &#x27;brand&#x27;, &#x27;container&#x27;,\n","                                  &#x27;capacity&#x27;, &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;]),\n","                                (&#x27;Numerico&#x27;,\n","                                 Pipeline(steps=[(&#x27;Logaritmic scaler&#x27;,\n","                                                  FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;,\n","                                                                      func=&lt;function to_log at 0x0000018E4D030B80&gt;)),\n","                                                 (&#x27;MinMax scaler&#x27;,\n","                                                  MinMaxScaler())]),\n","                                 [&#x27;lat&#x27;, &#x27;long&#x27;, &#x27;pop&#x27;, &#x27;price&#x27;])],\n","                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Categorico</label><div class=\"sk-toggleable__content\"><pre>[&#x27;date&#x27;, &#x27;city&#x27;, &#x27;shop&#x27;, &#x27;brand&#x27;, &#x27;container&#x27;, &#x27;capacity&#x27;, &#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Numerico</label><div class=\"sk-toggleable__content\"><pre>[&#x27;lat&#x27;, &#x27;long&#x27;, &#x27;pop&#x27;, &#x27;price&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(feature_names_out=&#x27;one-to-one&#x27;,\n","                    func=&lt;function to_log at 0x0000018E4D030B80&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["ColumnTransformer(remainder='passthrough',\n","                  transformers=[('Categorico',\n","                                 Pipeline(steps=[('Encoder',\n","                                                  OneHotEncoder(sparse_output=False))]),\n","                                 ['date', 'city', 'shop', 'brand', 'container',\n","                                  'capacity', 'year', 'month', 'day']),\n","                                ('Numerico',\n","                                 Pipeline(steps=[('Logaritmic scaler',\n","                                                  FunctionTransformer(feature_names_out='one-to-one',\n","                                                                      func=<function to_log at 0x0000018E4D030B80>)),\n","                                                 ('MinMax scaler',\n","                                                  MinMaxScaler())]),\n","                                 ['lat', 'long', 'pop', 'price'])],\n","                  verbose_feature_names_out=False)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Obteniendo librer칤as necesarias\n","from sklearn.model_selection import train_test_split \n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.dummy import DummyRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","# Definiendo la semilla\n","RANDOM_STATE = 42\n","\n","# Separando el conjunto de datos\n","X_train, X_rest, y_train, y_rest = train_test_split(df, df[\"quantity\"], test_size=.3, random_state=RANDOM_STATE)\n","X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=.33, random_state=RANDOM_STATE)\n","X_train.drop(columns=[\"id\", \"quantity\"], inplace=True)\n","X_val.drop(columns=[\"id\", \"quantity\"], inplace=True)\n","X_test.drop(columns=[\"id\", \"quantity\"], inplace=True)\n","\n","# Separando los datos en num칠ricos y categ칩ricos\n","num_cols = X_train.corr(numeric_only=True).columns.to_list()\n","cat_cols = [col for col in X_train.columns if not col in num_cols]\n","cat_cols.append(\"year\")  # Agregando las nuevas columnas que se obtendr치n del FunctionTransformer\n","cat_cols.append(\"month\")\n","cat_cols.append(\"day\")\n","\n","# Atributos num칠ricos\n","num_pipe = Pipeline([\n","                ('Logaritmic scaler', FunctionTransformer(to_log, feature_names_out='one-to-one')),\n","                ('MinMax scaler', MinMaxScaler())\n","            ])\n","# Atributos categ칩ricos\n","cat_pipe = Pipeline([\n","    ('Encoder', OneHotEncoder(sparse_output=False))\n","])\n","\n","# Creando ColumnTransformer\n","ctrans = ColumnTransformer(\n","        transformers=[\n","            (\"Categorico\", cat_pipe, cat_cols),\n","            (\"Numerico\", num_pipe, num_cols),\n","        ],\n","        remainder=\"passthrough\",\n","        verbose_feature_names_out=False\n",")\n","ctrans.set_output(transform='pandas')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE sobre conjunto de validaci칩n: 13308.134750658153\n"]}],"source":["# Pipeline de entrenamiento 1\n","pipe_train1 = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans),\n","    (\"Classifier\", DummyRegressor())\n","])\n","\n","# Entrenando\n","model1 = pipe_train1.fit(X_train, y_train)\n","\n","# Prediciendo\n","y_pred1 = model1.predict(X_val)\n","\n","# MAE\n","mae1 = mean_absolute_error(y_val, y_pred1)\n","print(f\"MAE sobre conjunto de validaci칩n: {mae1}\")"]},{"cell_type":"markdown","metadata":{},"source":["> El `mean_absolute_error` es una medida de diferencia entre el valor predicho y el valor real, siendo 칠sta el error absoluto medio entre ambos. Lo ideal es que esta m칠trica sea lo m치s cercana a 0 posible, ya que implicar칤a que el valor predicho no dista mucho del real, por lo que se tendr칤a una buena predicci칩n. \n","\n","> Dado que el valor obtenido del MAE es alrededor de 13000, se tiene que para la pipeline generada con `DummyRegressor` es de muy baja calidad, ya que los valores predichos est치n muy alejados de los valores reales. As칤, se tiene que el primer modelo generado es muy malo para la predicci칩n de la demanda de cantidad de ventas, por lo que la m칠trica estar칤a diciendo que este modelo no es bueno para el negocio."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE sobre conjunto de validaci칩n: 2500.3221446955317\n"]}],"source":["import xgboost as xgb\n","\n","# Pipeline de entrenamiento 2\n","pipe_train2 = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans),\n","    (\"Classifier\", xgb.XGBRegressor())\n","])\n","\n","# Entrenando\n","model2 = pipe_train2.fit(X_train, y_train)\n","\n","# Prediciendo\n","y_pred2 = model2.predict(X_val)\n","\n","# MAE\n","mae2 = mean_absolute_error(y_val, y_pred2)\n","print(f\"MAE sobre conjunto de validaci칩n: {mae2}\")"]},{"cell_type":"markdown","metadata":{},"source":["> Al cambiar el `DummyRegressor` por el `XGBRegressor`, se tiene una mejora instant치nea en la m칠trica, teniendo ahora un MAE de cerca de 2500, lo que es mucho m치s cercano a 0 que 13000. Este valor sigue indicando que el clasificador es malo para el negocio, pero muestra una inmediata mejora con el anterior."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["['models/default_xgb_model.pkl']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import joblib\n","\n","# Creando la carpeta de los modelos si es que no existe\n","if not os.path.exists(\"models\"):\n","    os.mkdir(\"models\")\n","\n","# Guardando los archivos en pkls separados\n","joblib.dump(model1, \"models/dummy_model.pkl\")\n","joblib.dump(model2, \"models/default_xgb_model.pkl\")"]},{"cell_type":"markdown","metadata":{"cell_id":"7e17e46063774ec28226fe300d42ffe0","deepnote_cell_type":"markdown"},"source":["## 1.2 Forzando relaciones entre par치metros con XGBoost (1.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n","</p>\n","\n","Un colega aficionado a la econom칤a le *sopla* que la demanda guarda una relaci칩n inversa con el precio del producto. Motivado para impresionar al querido corp칩reo, se propone hacer uso de esta informaci칩n para mejorar su modelo.\n","\n","Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relaci칩n mon칩tona negativa entre el precio y la cantidad. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci칩n. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo?\n","\n","Nuevamente, guarde su modelo en un archivo .pkl\n","\n","Nota: Para realizar esta parte, debe apoyarse en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci칩n</a>.\n","\n","Hint: Para implementar el constraint, se le sugiere hacerlo especificando el nombre de la variable. De ser as칤, probablemente le sea 칰til **mantener el formato de pandas** antes del step de entrenamiento."]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"f469f3b572be434191d2d5c3f11b20d2","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE sobre conjunto de validaci칩n: 2707.9117589321568\n"]}],"source":["# Pipeline de entrenamiento 3\n","pipe_train3 = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans),\n","    (\"Classifier\", xgb.XGBRegressor(monotone_constraints={'price': -1}))\n","])\n","\n","# Entrenando\n","model3 = pipe_train3.fit(X_train, y_train)\n","\n","# Prediciendo\n","y_pred3 = model3.predict(X_val)\n","\n","# MAE\n","mae3 = mean_absolute_error(y_val, y_pred3)\n","print(f\"MAE sobre conjunto de validaci칩n: {mae3}\")"]},{"cell_type":"markdown","metadata":{},"source":["> Al incluir esta relaci칩n, el error aument칩, lo que indica que empeor칩 el modelo. Esto es esperable, puesto que, mientras que es cierto que la demanda por lo general disminuye al momento de aumentar los precios, esta relaci칩n no es lineal. Esto quiere decir que no es directa la relaci칩n inversa que tienen, por lo que al definirla as칤, se tiene que el modelo empeorar치 ya que no es el comportamiento real de la demanda el que se estar칤a modelando, sino que una simplificaci칩n muy grande de 칠ste."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["['models/constraint_xgb_model.pkl']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Guardando el modelo\n","joblib.dump(model3, \"models/constraint_xgb_model.pkl\")"]},{"cell_type":"markdown","metadata":{"cell_id":"e59ef80ed20b4de8921f24da74e87374","deepnote_cell_type":"markdown"},"source":["## 1.3 Optimizaci칩n de Hiperpar치metros con Optuna (2.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n","</p>\n","\n","Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m치s* su modelo. En particular, le comenta de la optimizaci칩n de hiperpar치metros con metodolog칤as bayesianas a trav칠s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n","\n","A partir de la mejor configuraci칩n obtenida en la secci칩n anterior, utilice `optuna` para optimizar sus hiperpar치metros. En particular, se le pide:\n","\n","- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n","- Utilice `TPESampler` como m칠todo de muestreo\n","- De `XGBRegressor`, optimice los siguientes hiperpar치metros:\n","    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n","    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n","    - `max_depth` buscando valores enteros en el rango (3, 10)\n","    - `max_leaves` buscando valores enteros en el rango (0, 100)\n","    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n","    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n","    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n","- De `OneHotEncoder`, optimice el hiperpar치metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n","- Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados?\n","- Fije el tiempo de entrenamiento a 5 minutos\n","- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n","- Guardar su modelo en un archivo .pkl"]},{"cell_type":"markdown","metadata":{},"source":["**Explicaciones de los hiperpar치metros**\n","\n","* `min_frequency`: Es la frecuencia m칤nima que debe tener una categor칤a para que se considere en el modelo. Al ser un flotante, corresponde al porcentaje de frecuencia m칤nimo para considerarlo y se obtiene multiplicando este par치metro con el n칰mero de muestras.\n","* `learning_rate`: El learning rate corresponde al tama침o de paso que se da en cada iteraci칩n del algoritmo. Este valor es multiplicado por el gradiente de la funci칩n de p칠rdida, por lo que se tiene que, mientras m치s peque침o sea este valor, m치s peque침o ser치 el paso que se da en cada iteraci칩n y m치s tardar치 el entrenamiento. El rango es adecuado para este hiperpar치metro, siendo 0.1 un m치ximo bien razonable dentro del entrenamiento.\n","* `n_estimators`: El n칰mero de estimadores corresponde a la cantidad de 치rboles que se construyen en el algoritmo. De esta manera, se tiene que, mientras m치s grande sea este valor, m치s complejo ser치 el modelo y m치s tardar치 el entrenamiento. El rango hace sentido ya que son enteros, \n","* `max_depth`: Es la profundidad de cada 치rbol. En cierta forma, es la cantidad de preguntas que se le hacen al modelo para que 칠ste pueda predecir. La profundidad entre 3 y 10 resulta coherente, ya que se tiene que, mientras m치s profundo sea el 치rbol, m치s complejo ser치 el modelo y m치s tardar치 el entrenamiento, por lo que 10 resulta razonable como un m치ximo de capas.\n","* `max_leaves`: Corresponde al n칰mero m치ximo de hojas del 치rbol resultante. De cierta manera, regula la complejidad del modelo al igual que max_depth, pero de una manera m치s directa. El rango es razonable; sin embargo, se recomienda que sea menor a 64 para no ralentizar el entrenamiento demasiado.\n","* `min_child_weight`: Es el peso m칤nimo que debe tener un nodo para que se divida. Este hiperpar치metro regula la complejidad del modelo, ya que mientras m치s grande sea este valor, m치s nodos se descartar치n y m치s simple ser치 el modelo. Debido a la naturaleza del modelo, el rango es adecuado, aunque incluso existen algunos modelos donde 200 sea un valor razonable.\n","* `reg_alpha`: Regularizaci칩n L1 a los pesos de los nodos. Este penaliza el valor absoluto de los pesos o coeficientes, ayudando a hacer el modelo m치s robusto y evitar el esparcimiento al promover que algunos pesos de anulen al ser menos importantes. El rango de este varia entre 0 y 1, siendo 0 una penalizaci칩n nula.\n","* `reg_lambda`: Regularizaci칩n L2 a los pesos de los nodos. Este penaliza el valor cuadr치tico de los pesos o coeficientes, lo que ayuda a prevenir el overfitting al suavizar los pesos que se escapan del resto, limitando la magnitud de ellos. El rango de este varia entre 0 y 1, siendo 0 una penalizaci칩n nula, al igual que el anterior."]},{"cell_type":"code","execution_count":11,"metadata":{"cell_id":"de5914621cc64cb0b1bacb9ff565a97e","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\sanfe\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# Creando la optimizaci칩n con Optuna\n","import optuna\n","\n","def objective(trial):\n","    \"\"\"\n","    Funci칩n objetivo para optimizar los hiperpar치metros del modelo. Utiliza la libreria Optuna.\n","\n","    Parameters\n","    ----------\n","    trial : optuna.trial._trial.Trial\n","        Objeto de la clase Trial de Optuna.\n","\n","    Returns\n","    -------\n","    mae_opt : float\n","        Error absoluto medio del modelo optimizado. Es el valor que se intenta minimizar.\n","    \"\"\"\n","    # Agregando valores a probar\n","    min_frequency = trial.suggest_float('min_frequency', 0, 1)\n","    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1)\n","    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n","    max_depth = trial.suggest_int('max_depth', 3, 10)\n","    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n","    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n","    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n","    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n","\n","    # Re-editando el OneHotEncoder de ColumnTransformer\n","    cat_pipe = Pipeline([\n","        ('Encoder', OneHotEncoder(min_frequency=min_frequency, sparse_output=False))\n","    ])\n","\n","    ctrans = ColumnTransformer(\n","            transformers=[\n","                (\"Categorico\", cat_pipe, cat_cols),\n","                (\"Numerico\", num_pipe, num_cols),\n","            ],\n","            remainder=\"passthrough\",\n","            verbose_feature_names_out=False\n","    )\n","    ctrans.set_output(transform='pandas')\n","\n","    # Mejor de los 3 pipelines anteriores: pipeline 2\n","    pipe_train2 = Pipeline([\n","        (\"Date extraction\", FunctionTransformer(extract_date)),\n","        (\"Scaling\", ctrans),\n","        (\"Classifier\", xgb.XGBRegressor(learning_rate=learning_rate,\n","                                        n_estimators=n_estimators,\n","                                        max_depth=max_depth,\n","                                        max_leaves=max_leaves,\n","                                        min_child_weight=min_child_weight,\n","                                        reg_alpha=reg_alpha,\n","                                        reg_lambda=reg_lambda))\n","    ])\n","\n","    # Entrenando el pipeline\n","    model_opt = pipe_train2.fit(X_train, y_train)\n","\n","    # Prediciendo\n","    y_pred_opt = model_opt.predict(X_val)\n","\n","    # Obteniendo el MAE\n","    mae_opt = mean_absolute_error(y_val, y_pred_opt)\n","\n","    return mae_opt"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-11-16 23:24:32,435] A new study created in memory with name: no-name-925c7de2-9857-47d5-961d-cb07ebe0b09a\n","[I 2023-11-16 23:24:36,697] Trial 0 finished with value: 9126.717615023155 and parameters: {'min_frequency': 0.5488135039273248, 'learning_rate': 0.07180374727086954, 'n_estimators': 623, 'max_depth': 7, 'max_leaves': 42, 'min_child_weight': 4, 'reg_alpha': 0.4375872112626925, 'reg_lambda': 0.8917730007820798}. Best is trial 0 with value: 9126.717615023155.\n","[I 2023-11-16 23:24:40,846] Trial 1 finished with value: 8930.980045333883 and parameters: {'min_frequency': 0.9636627605010293, 'learning_rate': 0.038960710363751996, 'n_estimators': 802, 'max_depth': 7, 'max_leaves': 57, 'min_child_weight': 5, 'reg_alpha': 0.07103605819788694, 'reg_lambda': 0.08712929970154071}. Best is trial 1 with value: 8930.980045333883.\n","[I 2023-11-16 23:24:48,475] Trial 2 finished with value: 2017.3263964582986 and parameters: {'min_frequency': 0.02021839744032572, 'learning_rate': 0.08342936470924586, 'n_estimators': 790, 'max_depth': 9, 'max_leaves': 98, 'min_child_weight': 4, 'reg_alpha': 0.46147936225293185, 'reg_lambda': 0.7805291762864555}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:49,907] Trial 3 finished with value: 5743.61294095252 and parameters: {'min_frequency': 0.11827442586893322, 'learning_rate': 0.06435218111142486, 'n_estimators': 186, 'max_depth': 10, 'max_leaves': 52, 'min_child_weight': 3, 'reg_alpha': 0.26455561210462697, 'reg_lambda': 0.7742336894342167}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:50,608] Trial 4 finished with value: 8393.085915986941 and parameters: {'min_frequency': 0.45615033221654855, 'learning_rate': 0.05727496093799621, 'n_estimators': 67, 'max_depth': 7, 'max_leaves': 61, 'min_child_weight': 4, 'reg_alpha': 0.9437480785146242, 'reg_lambda': 0.6818202991034834}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:52,457] Trial 5 finished with value: 8388.83419461626 and parameters: {'min_frequency': 0.359507900573786, 'learning_rate': 0.044266163426134805, 'n_estimators': 713, 'max_depth': 3, 'max_leaves': 67, 'min_child_weight': 4, 'reg_alpha': 0.2103825610738409, 'reg_lambda': 0.1289262976548533}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:55,522] Trial 6 finished with value: 6713.059357137642 and parameters: {'min_frequency': 0.31542835092418386, 'learning_rate': 0.03700736632331964, 'n_estimators': 592, 'max_depth': 6, 'max_leaves': 99, 'min_child_weight': 1, 'reg_alpha': 0.2088767560948347, 'reg_lambda': 0.16130951788499626}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:57,151] Trial 7 finished with value: 8326.14631911559 and parameters: {'min_frequency': 0.6531083254653984, 'learning_rate': 0.02607586865143843, 'n_estimators': 493, 'max_depth': 4, 'max_leaves': 16, 'min_child_weight': 1, 'reg_alpha': 0.6563295894652734, 'reg_lambda': 0.1381829513486138}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:24:59,768] Trial 8 finished with value: 5657.757001339514 and parameters: {'min_frequency': 0.1965823616800535, 'learning_rate': 0.03750379189543545, 'n_estimators': 830, 'max_depth': 3, 'max_leaves': 84, 'min_child_weight': 1, 'reg_alpha': 0.9764594650133958, 'reg_lambda': 0.4686512016477016}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:25:01,593] Trial 9 finished with value: 8437.767673629944 and parameters: {'min_frequency': 0.9767610881903371, 'learning_rate': 0.060879706454759555, 'n_estimators': 753, 'max_depth': 3, 'max_leaves': 28, 'min_child_weight': 1, 'reg_alpha': 0.29614019752214493, 'reg_lambda': 0.11872771895424405}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:25:04,478] Trial 10 finished with value: 4942.809655488731 and parameters: {'min_frequency': 0.020334471624930517, 'learning_rate': 0.09852046649678155, 'n_estimators': 956, 'max_depth': 10, 'max_leaves': 2, 'min_child_weight': 3, 'reg_alpha': 0.6022694078738563, 'reg_lambda': 0.9644831755618566}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:25:08,121] Trial 11 finished with value: 2783.72975743374 and parameters: {'min_frequency': 0.013048945064446538, 'learning_rate': 0.09939800254634318, 'n_estimators': 950, 'max_depth': 10, 'max_leaves': 6, 'min_child_weight': 3, 'reg_alpha': 0.6038510599523575, 'reg_lambda': 0.9940070913069738}. Best is trial 2 with value: 2017.3263964582986.\n","[I 2023-11-16 23:25:16,935] Trial 12 finished with value: 1986.8998327522634 and parameters: {'min_frequency': 0.013057447356600709, 'learning_rate': 0.09745282164666788, 'n_estimators': 954, 'max_depth': 9, 'max_leaves': 81, 'min_child_weight': 2, 'reg_alpha': 0.498167285369409, 'reg_lambda': 0.9859882238544003}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:20,406] Trial 13 finished with value: 6728.731746250861 and parameters: {'min_frequency': 0.19863360395318855, 'learning_rate': 0.08492643336476893, 'n_estimators': 434, 'max_depth': 9, 'max_leaves': 97, 'min_child_weight': 2, 'reg_alpha': 0.4641406064936066, 'reg_lambda': 0.789372499594353}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:28,060] Trial 14 finished with value: 1996.233344328897 and parameters: {'min_frequency': 0.021305415485054713, 'learning_rate': 0.07831117261323023, 'n_estimators': 973, 'max_depth': 8, 'max_leaves': 81, 'min_child_weight': 2, 'reg_alpha': 0.40751281926357574, 'reg_lambda': 0.6129243749793609}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:34,796] Trial 15 finished with value: 5726.788302371912 and parameters: {'min_frequency': 0.16973355918529887, 'learning_rate': 0.00395589684037638, 'n_estimators': 986, 'max_depth': 8, 'max_leaves': 77, 'min_child_weight': 2, 'reg_alpha': 0.005967578926037054, 'reg_lambda': 0.5575254986897987}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:36,359] Trial 16 finished with value: 6641.722882789031 and parameters: {'min_frequency': 0.2669421392728392, 'learning_rate': 0.08054373462948097, 'n_estimators': 338, 'max_depth': 5, 'max_leaves': 80, 'min_child_weight': 2, 'reg_alpha': 0.7437473540348526, 'reg_lambda': 0.44994987646260187}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:41,824] Trial 17 finished with value: 6317.668767748274 and parameters: {'min_frequency': 0.0996974448189078, 'learning_rate': 0.08763597346224061, 'n_estimators': 898, 'max_depth': 8, 'max_leaves': 38, 'min_child_weight': 2, 'reg_alpha': 0.37007959829076015, 'reg_lambda': 0.6042231013694808}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:47,217] Trial 18 finished with value: 6406.686771978523 and parameters: {'min_frequency': 0.09058465380330731, 'learning_rate': 0.07314602158112969, 'n_estimators': 659, 'max_depth': 8, 'max_leaves': 68, 'min_child_weight': 2, 'reg_alpha': 0.5402630578666935, 'reg_lambda': 0.3848663811972053}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:52,936] Trial 19 finished with value: 7630.8168954683715 and parameters: {'min_frequency': 0.23977006109459098, 'learning_rate': 0.09033386439003144, 'n_estimators': 877, 'max_depth': 9, 'max_leaves': 87, 'min_child_weight': 3, 'reg_alpha': 0.3982285165958367, 'reg_lambda': 0.8417652166380098}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:25:57,146] Trial 20 finished with value: 9595.106051232373 and parameters: {'min_frequency': 0.37861434588972287, 'learning_rate': 0.07166768803459687, 'n_estimators': 994, 'max_depth': 6, 'max_leaves': 74, 'min_child_weight': 2, 'reg_alpha': 0.3381121448805884, 'reg_lambda': 0.6689222844016085}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:07,685] Trial 21 finished with value: 2151.522839208789 and parameters: {'min_frequency': 0.009487226914815218, 'learning_rate': 0.09225535043635506, 'n_estimators': 847, 'max_depth': 9, 'max_leaves': 91, 'min_child_weight': 5, 'reg_alpha': 0.4989584483998449, 'reg_lambda': 0.9082842679263758}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:17,274] Trial 22 finished with value: 2170.2192123677924 and parameters: {'min_frequency': 0.0022652556785879296, 'learning_rate': 0.07939217498900059, 'n_estimators': 744, 'max_depth': 9, 'max_leaves': 91, 'min_child_weight': 4, 'reg_alpha': 0.4559120844903792, 'reg_lambda': 0.7692581990480446}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:23,726] Trial 23 finished with value: 6752.607305997841 and parameters: {'min_frequency': 0.10668584756384228, 'learning_rate': 0.09999680436133582, 'n_estimators': 898, 'max_depth': 8, 'max_leaves': 72, 'min_child_weight': 3, 'reg_alpha': 0.3684145588267173, 'reg_lambda': 0.8921400104804674}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:29,775] Trial 24 finished with value: 6716.7113037109375 and parameters: {'min_frequency': 0.14336394845200642, 'learning_rate': 0.08346534510690193, 'n_estimators': 794, 'max_depth': 9, 'max_leaves': 99, 'min_child_weight': 5, 'reg_alpha': 0.4944130829323471, 'reg_lambda': 0.9954112384757989}. Best is trial 12 with value: 1986.8998327522634.\n","[I 2023-11-16 23:26:38,570] Trial 25 finished with value: 1951.8277633524388 and parameters: {'min_frequency': 0.07635478834392678, 'learning_rate': 0.09032442930563103, 'n_estimators': 913, 'max_depth': 8, 'max_leaves': 83, 'min_child_weight': 3, 'reg_alpha': 0.5590535826737515, 'reg_lambda': 0.6940799730661463}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:26:51,549] Trial 26 finished with value: 7698.152440599511 and parameters: {'min_frequency': 0.2732263050685856, 'learning_rate': 0.0922509057180985, 'n_estimators': 902, 'max_depth': 8, 'max_leaves': 82, 'min_child_weight': 3, 'reg_alpha': 0.727393307583318, 'reg_lambda': 0.688461577672377}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:04,976] Trial 27 finished with value: 2016.7320866298294 and parameters: {'min_frequency': 0.07716820944890182, 'learning_rate': 0.07684765352404443, 'n_estimators': 1000, 'max_depth': 7, 'max_leaves': 64, 'min_child_weight': 2, 'reg_alpha': 0.5468161355332433, 'reg_lambda': 0.5658751951792086}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:09,694] Trial 28 finished with value: 7123.846192058161 and parameters: {'min_frequency': 0.2097395568897438, 'learning_rate': 0.09219778809987268, 'n_estimators': 681, 'max_depth': 6, 'max_leaves': 46, 'min_child_weight': 2, 'reg_alpha': 0.40218838455170747, 'reg_lambda': 0.694611196031858}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:13,994] Trial 29 finished with value: 6113.721425768212 and parameters: {'min_frequency': 0.13599260137771899, 'learning_rate': 0.06541762109912105, 'n_estimators': 599, 'max_depth': 7, 'max_leaves': 55, 'min_child_weight': 3, 'reg_alpha': 0.42890629128150703, 'reg_lambda': 0.859420356034406}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:22,057] Trial 30 finished with value: 1987.7507200355683 and parameters: {'min_frequency': 0.0706634467175034, 'learning_rate': 0.07168499308197432, 'n_estimators': 915, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 1, 'reg_alpha': 0.5353747357065575, 'reg_lambda': 0.9287062763452252}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:30,565] Trial 31 finished with value: 1981.618513160777 and parameters: {'min_frequency': 0.06775685577857174, 'learning_rate': 0.07307303457849289, 'n_estimators': 929, 'max_depth': 8, 'max_leaves': 89, 'min_child_weight': 1, 'reg_alpha': 0.5345238968215354, 'reg_lambda': 0.9289253897002412}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:38,385] Trial 32 finished with value: 5444.596490144411 and parameters: {'min_frequency': 0.08416472170607733, 'learning_rate': 0.07089983736470647, 'n_estimators': 910, 'max_depth': 7, 'max_leaves': 90, 'min_child_weight': 1, 'reg_alpha': 0.5434606089108242, 'reg_lambda': 0.9280173459134533}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:45,129] Trial 33 finished with value: 6616.8968588163125 and parameters: {'min_frequency': 0.15232840637535372, 'learning_rate': 0.08617841795325297, 'n_estimators': 831, 'max_depth': 8, 'max_leaves': 93, 'min_child_weight': 1, 'reg_alpha': 0.6191839391730279, 'reg_lambda': 0.9578591592847099}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:52,362] Trial 34 finished with value: 1980.5381110360688 and parameters: {'min_frequency': 0.06761634774174481, 'learning_rate': 0.06829630848947744, 'n_estimators': 779, 'max_depth': 10, 'max_leaves': 72, 'min_child_weight': 1, 'reg_alpha': 0.5365609639643151, 'reg_lambda': 0.8742412980609915}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:27:58,057] Trial 35 finished with value: 6379.291342232352 and parameters: {'min_frequency': 0.16363515592960237, 'learning_rate': 0.06682603010619002, 'n_estimators': 776, 'max_depth': 10, 'max_leaves': 71, 'min_child_weight': 1, 'reg_alpha': 0.4789667474411971, 'reg_lambda': 0.8477998270111955}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:05,647] Trial 36 finished with value: 2053.351215194478 and parameters: {'min_frequency': 0.07527259394284794, 'learning_rate': 0.05698579780216279, 'n_estimators': 855, 'max_depth': 10, 'max_leaves': 61, 'min_child_weight': 1, 'reg_alpha': 0.6937668363051048, 'reg_lambda': 0.8824046278364724}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:10,691] Trial 37 finished with value: 7327.105006708163 and parameters: {'min_frequency': 0.23247560619644547, 'learning_rate': 0.0780670288620528, 'n_estimators': 714, 'max_depth': 9, 'max_leaves': 77, 'min_child_weight': 1, 'reg_alpha': 0.5755827791298328, 'reg_lambda': 0.8092286106299579}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:12,832] Trial 38 finished with value: 6894.152823067476 and parameters: {'min_frequency': 0.3173974428464182, 'learning_rate': 0.09541461493663626, 'n_estimators': 246, 'max_depth': 10, 'max_leaves': 85, 'min_child_weight': 2, 'reg_alpha': 0.6369605724247737, 'reg_lambda': 0.9995769958634034}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:17,183] Trial 39 finished with value: 2079.5616513750106 and parameters: {'min_frequency': 0.04850481474884455, 'learning_rate': 0.08592244820379323, 'n_estimators': 522, 'max_depth': 9, 'max_leaves': 57, 'min_child_weight': 4, 'reg_alpha': 0.65913309470509, 'reg_lambda': 0.7483551430621875}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:23,243] Trial 40 finished with value: 6652.474456827854 and parameters: {'min_frequency': 0.13155861406098457, 'learning_rate': 0.09454489060341995, 'n_estimators': 810, 'max_depth': 9, 'max_leaves': 77, 'min_child_weight': 1, 'reg_alpha': 0.7760631695435911, 'reg_lambda': 0.8366310628742767}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:32,124] Trial 41 finished with value: 1993.8648699568175 and parameters: {'min_frequency': 0.061882306115692474, 'learning_rate': 0.07369797400450741, 'n_estimators': 928, 'max_depth': 7, 'max_leaves': 94, 'min_child_weight': 1, 'reg_alpha': 0.5281903981068817, 'reg_lambda': 0.9309416834705204}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:41,915] Trial 42 finished with value: 2028.245370617855 and parameters: {'min_frequency': 0.05880274052932534, 'learning_rate': 0.08158664650672792, 'n_estimators': 861, 'max_depth': 8, 'max_leaves': 86, 'min_child_weight': 1, 'reg_alpha': 0.575741034657216, 'reg_lambda': 0.916035407254763}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:50,609] Trial 43 finished with value: 6609.840556288593 and parameters: {'min_frequency': 0.17926226048963725, 'learning_rate': 0.06775877650580238, 'n_estimators': 942, 'max_depth': 10, 'max_leaves': 87, 'min_child_weight': 1, 'reg_alpha': 0.5168228697053815, 'reg_lambda': 0.949193800978987}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:28:58,480] Trial 44 finished with value: 6344.549157014039 and parameters: {'min_frequency': 0.10548737726206583, 'learning_rate': 0.06128597809034258, 'n_estimators': 926, 'max_depth': 8, 'max_leaves': 66, 'min_child_weight': 1, 'reg_alpha': 0.4482515812234238, 'reg_lambda': 0.8788398686733475}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:11,043] Trial 45 finished with value: 2197.6040594816527 and parameters: {'min_frequency': 0.000436676809238706, 'learning_rate': 0.08923295921968599, 'n_estimators': 755, 'max_depth': 10, 'max_leaves': 96, 'min_child_weight': 2, 'reg_alpha': 0.5896908719350288, 'reg_lambda': 0.7992902278626857}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:19,402] Trial 46 finished with value: 2024.7219604981121 and parameters: {'min_frequency': 0.04015931783596217, 'learning_rate': 0.05435580672377532, 'n_estimators': 829, 'max_depth': 9, 'max_leaves': 81, 'min_child_weight': 1, 'reg_alpha': 0.49196448685204974, 'reg_lambda': 0.9584794520623106}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:26,234] Trial 47 finished with value: 6286.021649960364 and parameters: {'min_frequency': 0.12812690452045666, 'learning_rate': 0.06120062201792585, 'n_estimators': 955, 'max_depth': 6, 'max_leaves': 100, 'min_child_weight': 1, 'reg_alpha': 0.4425090736667596, 'reg_lambda': 0.9059972947298723}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:27,179] Trial 48 finished with value: 3044.656306553269 and parameters: {'min_frequency': 0.04696158407280705, 'learning_rate': 0.09586460933984163, 'n_estimators': 67, 'max_depth': 7, 'max_leaves': 37, 'min_child_weight': 2, 'reg_alpha': 0.6541959075220233, 'reg_lambda': 0.7492156683743074}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:30,758] Trial 49 finished with value: 5939.746433069614 and parameters: {'min_frequency': 0.1898536821803897, 'learning_rate': 0.08265171126394048, 'n_estimators': 656, 'max_depth': 5, 'max_leaves': 70, 'min_child_weight': 3, 'reg_alpha': 0.5641775239038888, 'reg_lambda': 0.9993200258497689}. Best is trial 25 with value: 1951.8277633524388.\n","[I 2023-11-16 23:29:33,816] Trial 50 finished with value: 5788.450802404508 and parameters: {'min_frequency': 0.11202481434223271, 'learning_rate': 0.07575219257584644, 'n_estimators': 443, 'max_depth': 8, 'max_leaves': 24, 'min_child_weight': 1, 'reg_alpha': 0.5141631526272215, 'reg_lambda': 0.8266626331588254}. Best is trial 25 with value: 1951.8277633524388.\n"]}],"source":["# Seteando semilla de optuna\n","optuna_seed = 0\n","\n","# Sampler\n","sampler = optuna.samplers.TPESampler(seed=optuna_seed)\n","\n","# Generando el estudio de hiperpar치metros\n","study = optuna.create_study(direction='minimize', sampler=sampler)\n","study.optimize(objective, timeout=300)  # 5 min de entrenamiento"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de trials hechos: 51 \n","Mejor MAE obtenido: 1951.8277633524388 \n","Mejores hiperpar치metros: {'min_frequency': 0.07635478834392678, 'learning_rate': 0.09032442930563103, 'n_estimators': 913, 'max_depth': 8, 'max_leaves': 83, 'min_child_weight': 3, 'reg_alpha': 0.5590535826737515, 'reg_lambda': 0.6940799730661463}\n"]}],"source":["# Obteniendo la cantidad de trials, el mejor MAE y los mejores hiperpar치metros\n","n_trails = len(study.trials)\n","best_mae = study.best_value\n","best_hp = study.best_params\n","print(f\"Cantidad de trials hechos: {n_trails} \\nMejor MAE obtenido: {best_mae} \\nMejores hiperpar치metros: {best_hp}\")"]},{"cell_type":"markdown","metadata":{},"source":["> El MAE mejor칩 considerablemente, lo que indica que el modelo es mucho mejor que el anterior. Esto se debe a que se optimizaron los hiperpar치metros, complejizando el modelo y la interrelaci칩n de los par치metros con el entrenamiento, adecuandolo a los datos. As칤, se tiene que el modelo es mucho mejor que el anterior, ya que se optimizaron los hiperpar치metros para que se ajusten mejor a los datos."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["['models/best_xgb_model1.pkl']"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Obteniendo el mejor modelo\n","cat_pipe_best = Pipeline([\n","    ('Encoder', OneHotEncoder(min_frequency=best_hp['min_frequency'], sparse_output=False))\n","])\n","\n","ctrans_best = ColumnTransformer(\n","        transformers=[\n","            (\"Categorico\", cat_pipe_best, cat_cols),\n","            (\"Numerico\", num_pipe, num_cols),\n","        ],\n","        remainder=\"passthrough\",\n","        verbose_feature_names_out=False\n",")\n","ctrans_best.set_output(transform='pandas')\n","\n","# Mejor pipeline\n","pipe_train_best = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans_best),\n","    (\"Classifier\", xgb.XGBRegressor(learning_rate=best_hp['learning_rate'],\n","                                    n_estimators=best_hp['n_estimators'],\n","                                    max_depth=best_hp['max_depth'],\n","                                    max_leaves=best_hp['max_leaves'],\n","                                    min_child_weight=best_hp['min_child_weight'],\n","                                    reg_alpha=best_hp['reg_alpha'],\n","                                    reg_lambda=best_hp['reg_lambda']))\n","])\n","\n","# Entrenando el mejor pipeline\n","model_best = pipe_train_best.fit(X_train, y_train)\n","\n","# Guardando el mejor modelo\n","joblib.dump(model_best, \"models/best_xgb_model1.pkl\")"]},{"cell_type":"markdown","metadata":{"cell_id":"5195ccfc37e044ad9453f6eb2754f631","deepnote_cell_type":"markdown"},"source":["## 1.4 Optimizaci칩n de Hiperpar치metros con Optuna y Prunners (1.7)\n","\n","<p align=\"center\">\n","  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n","</p>\n","\n","Despu칠s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s칤 mismo. Despu칠s de leer un par de post de personas de dudosa reputaci칩n en la *deepweb*, usted llega a la conclusi칩n que puede cumplir este objetivo mediante la implementaci칩n de **Prunning**.\n","\n","Vuelva a optimizar los mismos hiperpar치metros que la secci칩n pasada, pero esta vez utilizando **Prunning** en la optimizaci칩n. En particular, usted debe:\n","\n","- Responder: 쯈u칠 es prunning? 쮻e qu칠 forma deber칤a impactar en el entrenamiento?\n","- Utilizar `optuna.integration.XGBoostPruningCallback` como m칠todo de **Prunning**\n","- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n","- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n","- Guardar su modelo en un archivo .pkl\n","\n","Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n","\n","```\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","```\n","\n","De implementar la opci칩n anterior, pueden especificar `show_progress_bar = True` en el m칠todo `optimize` para *m치s sabor*.\n","\n","Hint: Si quieren especificar par치metros del m칠todo .fit() del modelo a trav칠s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n","\n","Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci칩n"]},{"cell_type":"markdown","metadata":{},"source":["> Prunning o \"poda\" es una forma de simplificar o reducir la estructura de un modelo con el fin de mejorar su rendimiento. Esto se hace eliminando nodos o ramas del modelo, lo que ayuda a reducir el overfitting y la complejidad del modelo. Al hacer esto, se espera que la capacidad de generalizaci칩n frente a datos nuevos sea aun mayor y, por otro lado, mejorar la eficiencia computacional del modelo al hacerlo \"menos costoso\" de entrenar."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Creando la optimizaci칩n con Optuna\n","\n","def objective2(trial):\n","    \"\"\"\n","    Funci칩n objetivo para optimizar los hiperpar치metros del modelo. Utiliza la libreria Optuna y m칠todo Prunning.\n","\n","    Parameters\n","    ----------\n","    trial : optuna.trial._trial.Trial\n","        Objeto de la clase Trial de Optuna.\n","\n","    Returns\n","    -------\n","    mae_opt : float\n","        Error absoluto medio del modelo optimizado. Es el valor que se intenta minimizar.\n","    \"\"\"\n","    # Agregando valores a probar\n","    min_frequency = trial.suggest_float('min_frequency', 0, 1)\n","    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-1)\n","    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n","    max_depth = trial.suggest_int('max_depth', 3, 10)\n","    max_leaves = trial.suggest_int('max_leaves', 0, 100)\n","    min_child_weight = trial.suggest_int('min_child_weight', 1, 5)\n","    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n","    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n","\n","    # Re-editando el OneHotEncoder de ColumnTransformer\n","    cat_pipe = Pipeline([\n","        ('Encoder', OneHotEncoder(min_frequency=min_frequency, sparse_output=False))\n","    ])\n","\n","    ctrans = ColumnTransformer(\n","            transformers=[\n","                (\"Categorico\", cat_pipe, cat_cols),\n","                (\"Numerico\", num_pipe, num_cols),\n","            ],\n","            remainder=\"passthrough\",\n","            verbose_feature_names_out=False\n","    )\n","    ctrans.set_output(transform='pandas')\n","\n","    # Definiendo el prunning\n","    pruning_callback = optuna.integration.XGBoostPruningCallback(\n","        trial, observation_key=\"validation_1-mae\"\n","    )\n","\n","    # Mejor de los 3 pipelines anteriores: pipeline 2\n","    pipe_train2 = Pipeline([\n","        (\"Date extraction\", FunctionTransformer(extract_date)),\n","        (\"Scaling\", ctrans),\n","        (\"Classifier\", xgb.XGBRegressor(learning_rate=learning_rate,\n","                                        n_estimators=n_estimators,\n","                                        max_depth=max_depth,\n","                                        max_leaves=max_leaves,\n","                                        min_child_weight=min_child_weight,\n","                                        reg_alpha=reg_alpha,\n","                                        reg_lambda=reg_lambda,\n","                                        eval_metric='mae',\n","                                        early_stopping_rounds=10,\n","                                        callbacks=[pruning_callback]))\n","    ])\n","\n","    # Paso necesario\n","    pipe_dumb = Pipeline([\n","        (\"Date extraction\", FunctionTransformer(extract_date)),\n","        (\"Scaling\", ctrans)\n","    ])\n","    step = pipe_dumb.fit(X_train, y_train)\n","    X_train2 = step.transform(X_train)\n","    X_val2 = step.transform(X_val)\n","\n","    # Entrenando el pipeline\n","    model_opt = pipe_train2.fit(X_train,\n","                                y_train,\n","                                Classifier__eval_set=[(X_train2, y_train), (X_val2, y_val)],\n","                                Classifier__verbose=False)\n","\n","    # Prediciendo\n","    y_pred_opt = model_opt.predict(X_val)\n","\n","    # Obteniendo el MAE\n","    mae_opt = mean_absolute_error(y_val, y_pred_opt)\n","\n","    return mae_opt"]},{"cell_type":"code","execution_count":16,"metadata":{"cell_id":"eeaa967cd8f6426d8c54f276c17dce79","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["   0%|          | 00:00/05:00"]},{"name":"stderr","output_type":"stream","text":["Best trial: 12. Best value: 2029.99:  100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 05:00/05:00\n"]}],"source":["# Quitando los prints de prunning\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","# Generando el estudio de hiperpar치metros\n","study2 = optuna.create_study(direction='minimize', sampler=sampler)\n","study2.optimize(objective2, timeout=300, show_progress_bar=True)  # 5 min de entrenamiento"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cantidad de trials hechos: 129 \n","Mejor MAE obtenido: 2029.9910766438584 \n","Mejores hiperpar치metros: {'min_frequency': 0.03402343044784076, 'learning_rate': 0.09943651925920696, 'n_estimators': 415, 'max_depth': 10, 'max_leaves': 100, 'min_child_weight': 1, 'reg_alpha': 0.2104797919643507, 'reg_lambda': 0.03098980392770021}\n"]}],"source":["# Obteniendo la cantidad de trials, el mejor MAE y los mejores hiperpar치metros\n","n_trails2 = len(study2.trials)\n","best_mae2 = study2.best_value\n","best_hp2 = study2.best_params\n","print(f\"Cantidad de trials hechos: {n_trails2} \\nMejor MAE obtenido: {best_mae2} \\nMejores hiperpar치metros: {best_hp2}\")"]},{"cell_type":"markdown","metadata":{},"source":["> El MAE empeor칩 levemente en comparaci칩n al modelo optimizado anteriormente, ya que aument칩. Mientras que se espera que al quitar pruebas se evite el overfitting y as칤 tener una mejora del modelo, la variabilidad de los hiperpar치metros de forma aleatoria conlleva a que se tenga tambi칠n mayor variabilidad al momento de obtener su MAE. Al ir quitando pruebas, se van generando cada vez m치s trials, lo que aumenta la variabilidad de los par치metors, abriendo m치s posibilidades de resultados, lo que puede mejorar o empeorar el modelo. Para esta corrida, se empeor칩."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["['models/best_xgb_model2.pkl']"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Obteniendo el mejor modelo\n","cat_pipe_best2 = Pipeline([\n","    ('Encoder', OneHotEncoder(min_frequency=best_hp2['min_frequency'], sparse_output=False))\n","])\n","\n","ctrans_best2 = ColumnTransformer(\n","        transformers=[\n","            (\"Categorico\", cat_pipe_best2, cat_cols),\n","            (\"Numerico\", num_pipe, num_cols),\n","        ],\n","        remainder=\"passthrough\",\n","        verbose_feature_names_out=False\n",")\n","ctrans_best2.set_output(transform='pandas')\n","\n","# Mejor pipeline\n","pipe_train_best2 = Pipeline([\n","    (\"Date extraction\", FunctionTransformer(extract_date)),\n","    (\"Scaling\", ctrans_best2),\n","    (\"Classifier\", xgb.XGBRegressor(learning_rate=best_hp2['learning_rate'],\n","                                    n_estimators=best_hp2['n_estimators'],\n","                                    max_depth=best_hp2['max_depth'],\n","                                    max_leaves=best_hp2['max_leaves'],\n","                                    min_child_weight=best_hp2['min_child_weight'],\n","                                    reg_alpha=best_hp2['reg_alpha'],\n","                                    reg_lambda=best_hp2['reg_lambda']))\n","])\n","\n","# Entrenando el mejor pipeline\n","model_best2 = pipe_train_best2.fit(X_train, y_train)\n","\n","# Guardando el mejor modelo\n","joblib.dump(model_best2, \"models/best_xgb_model2.pkl\")"]},{"cell_type":"markdown","metadata":{"cell_id":"8a081778cc704fc6bed05393a5419327","deepnote_cell_type":"markdown"},"source":["## 1.5 Visualizaciones (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n","</p>\n","\n","\n","Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n","\n","A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n","\n","- Gr치fico de historial de optimizaci칩n\n","- Gr치fico de coordenadas paralelas\n","- Gr치fico de importancia de hiperpar치metros\n","\n","Comente sus resultados: 쮻esde qu칠 *trial* se empiezan a observar mejoras notables en sus resultados? 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas? 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo?"]},{"cell_type":"code","execution_count":19,"metadata":{"cell_id":"0e706dc9a8d946eda7a9eb1f0463c6d7","deepnote_cell_type":"code"},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"mode":"markers","name":"MAE","type":"scatter","x":[0,1,2,3,4,9,10,11,12,15,20,27,31,37,41,42,55,102,105,120,122,125],"y":[6341.053950514749,8296.199255582966,8634.110806596294,6274.878778149512,8343.942307190839,5687.3579463373035,2079.7774565305826,2277.847836992292,2029.9910766438584,5724.292463845022,5710.082753567256,5633.374085369033,5682.727604579543,5681.222166827906,5679.493011841309,2030.435602287425,2042.7986048455232,5678.356557441171,5673.777153717978,5669.160293803196,5674.0098904659335,2115.2486386471023]},{"mode":"lines","name":"Best Value","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128],"y":[6341.053950514749,6341.053950514749,6341.053950514749,6274.878778149512,6274.878778149512,6274.878778149512,6274.878778149512,6274.878778149512,6274.878778149512,5687.3579463373035,2079.7774565305826,2079.7774565305826,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584,2029.9910766438584]},{"marker":{"color":"#cccccc"},"mode":"markers","name":"Infeasible Trial","showlegend":false,"type":"scatter","x":[],"y":[]}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Optimization History Plot"},"xaxis":{"title":{"text":"Trial"}},"yaxis":{"title":{"text":"MAE"}}}}},"metadata":{},"output_type":"display_data"}],"source":["# Obteniendo las herramientas gr치ficas\n","from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_param_importances\n","\n","# Gr치fico de historial de optimizaci칩n\n","plot_optimization_history(study2, target_name=\"MAE\")"]},{"cell_type":"markdown","metadata":{},"source":["> Viendo el gr치fico, es posible ver mejoras notables desde el trial n칰mero 10. Mientras que hay una tendencia a subir el MAE a alrededor de los 6000, 칠ste oscila tambi칠n en los 2000, donde se encuentra el mejor valor."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"dimensions":[{"label":"MAE","range":[2029.9910766438584,8634.110806596294],"values":[6341.053950514749,8296.199255582966,8634.110806596294,6274.878778149512,8343.942307190839,5687.3579463373035,2079.7774565305826,2277.847836992292,2029.9910766438584,5724.292463845022,5710.082753567256,5633.374085369033,5682.727604579543,5681.222166827906,5679.493011841309,2030.435602287425,2042.7986048455232,5678.356557441171,5673.777153717978,5669.160293803196,5674.0098904659335,2115.2486386471023]},{"label":"learning_rate","range":[0.002990647072561862,0.09993220213590467],"values":[0.04201203645695233,0.0930003235600452,0.002990647072561862,0.058039576107365855,0.030446258134658236,0.06194039686410058,0.09359482400048519,0.09983177137679547,0.09943651925920696,0.09825950518836689,0.08824502651120517,0.09953709610997145,0.09960786067816955,0.09466906234372463,0.09626623251950868,0.09555890961631497,0.09951612393767433,0.09549350447836313,0.09780880623083119,0.09993220213590467,0.09985001454677227,0.09801466378525917]},{"label":"max_depth","range":[3,10],"values":[8,8,3,7,6,9,10,10,10,9,9,10,10,8,8,10,10,7,7,7,7,7]},{"label":"max_leaves","range":[13,100],"values":[57,13,68,22,88,81,100,100,100,77,67,46,48,93,92,100,96,91,98,83,83,86]},{"label":"min_child_weight","range":[1,5],"values":[2,4,2,5,3,3,1,1,1,1,4,2,2,2,2,4,1,4,1,3,3,3]},{"label":"min_frequency","range":[0.003905887857990814,0.6994792753175043],"values":[0.317983179393976,0.5759464955561793,0.5865129348100832,0.24875314351995803,0.6994792753175043,0.16249293467637482,0.03696509764442346,0.003905887857990814,0.03402343044784076,0.17915005741270484,0.09600766176834163,0.16833192680088038,0.08890841085194288,0.12655259987076176,0.14180755212732163,0.05499276882128483,0.05781127332453817,0.15646913911686364,0.11267377687323496,0.1287130670290348,0.16486596042455884,0.05734626081402613]},{"label":"n_estimators","range":[54,838],"values":[111,352,838,613,823,167,360,359,415,463,54,318,310,302,309,355,408,95,360,296,297,230]},{"label":"reg_alpha","range":[0.13284282828205216,0.8817353618548528],"values":[0.5232480534666997,0.2894060929472011,0.7351940221225949,0.44712537861762736,0.8817353618548528,0.40718329722599966,0.2666628387780338,0.24926003344538708,0.2104797919643507,0.3328337593283573,0.5961096743333528,0.2999158948305251,0.29696003008684224,0.25399355152191094,0.22904515996146946,0.13284282828205216,0.15721122349406685,0.5493405938079492,0.2030493915569775,0.27777120648286013,0.2726707939146492,0.28892602143010715]},{"label":"reg_lambda","range":[0.006592953321621478,0.9621885451174382],"values":[0.09394051075844168,0.18319136200711683,0.9621885451174382,0.8464086724711278,0.6925315900777659,0.06916699545513805,0.025735853373902648,0.006592953321621478,0.03098980392770021,0.38319223771168814,0.13518471690938821,0.16476970353052567,0.14338283639771165,0.19028429387991025,0.18574600895069301,0.0488955698251497,0.15012371856966114,0.11371446648391995,0.047107789081093435,0.17908225894256152,0.22541188950185642,0.1703222805856767]}],"labelangle":30,"labelside":"bottom","line":{"color":[6341.053950514749,8296.199255582966,8634.110806596294,6274.878778149512,8343.942307190839,5687.3579463373035,2079.7774565305826,2277.847836992292,2029.9910766438584,5724.292463845022,5710.082753567256,5633.374085369033,5682.727604579543,5681.222166827906,5679.493011841309,2030.435602287425,2042.7986048455232,5678.356557441171,5673.777153717978,5669.160293803196,5674.0098904659335,2115.2486386471023],"colorbar":{"title":{"text":"MAE"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"reversescale":true,"showscale":true},"type":"parcoords"}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Parallel Coordinate Plot"}}}},"metadata":{},"output_type":"display_data"}],"source":["# Gr치fico de coordenadas paralelas\n","plot_parallel_coordinate(study2, target_name=\"MAE\")"]},{"cell_type":"markdown","metadata":{},"source":["> De derecha a izquierda, se puede observar que los primeros hiperpar치metros tienen un comportamiento m치s err치tico (se prueban valores m치s distintos entre s칤), pero a medida que se avanza, se ve que algunos par치metros convergen a ciertos valores. Por ejemplo, `min_frequency` converge a valores menores que 0.1, `max_leaves` a valores sobre 80 y `learning_rate` a valores sobre 0.9. Este comportamiento se ve cada vez m치s pronunciado (es m치s fuerte la convergencia a estos valores) mientras m치s a la izquierda se est칠 llegando, coincidiendo con la convegencia d elos valores de la m칠trica de evaluaci칩n MAE. "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"cliponaxis":false,"hovertemplate":["min_child_weight (IntDistribution): 0.011093209321839948<extra></extra>","max_depth (IntDistribution): 0.01574958216139927<extra></extra>","n_estimators (IntDistribution): 0.01648848204120843<extra></extra>","learning_rate (FloatDistribution): 0.01841056138235843<extra></extra>","reg_lambda (FloatDistribution): 0.027948532410473282<extra></extra>","reg_alpha (FloatDistribution): 0.0362088735711912<extra></extra>","max_leaves (IntDistribution): 0.03898203101519217<extra></extra>","min_frequency (FloatDistribution): 0.8351187280963374<extra></extra>"],"name":"MAE","orientation":"h","text":["0.01","0.02","0.02","0.02","0.03","0.04","0.04","0.84"],"textposition":"outside","type":"bar","x":[0.011093209321839948,0.01574958216139927,0.01648848204120843,0.01841056138235843,0.027948532410473282,0.0362088735711912,0.03898203101519217,0.8351187280963374],"y":["min_child_weight","max_depth","n_estimators","learning_rate","reg_lambda","reg_alpha","max_leaves","min_frequency"]}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Hyperparameter Importance"}},"yaxis":{"title":{"text":"Hyperparameter"}}}}},"metadata":{},"output_type":"display_data"}],"source":["# Gr치fico de importancia de hiperpar치metros\n","plot_param_importances(study2, target_name=\"MAE\")"]},{"cell_type":"markdown","metadata":{},"source":["> El par치metro m치s importante por lejos es el `min_frequency`, puesto que define c칩mo ser치n los datos del pipeline a trav칠s del `OneHotEncoder`. Esto conlleva a que defina el resto de los par치metros del pipeline, ya que 칠ste se ajustar치 a los datos, los cuales depender치n de `min_frequency`."]},{"cell_type":"markdown","metadata":{"cell_id":"ac8a20f445d045a3becf1a518d410a7d","deepnote_cell_type":"markdown"},"source":["## 1.6 S칤ntesis de resultados (0.3)\n","\n","Finalmente, genere una tabla resumen del MAE obtenido en los 5 modelos entrenados (desde Baseline hasta XGBoost con Constraints, Optuna y Prunning) y compare sus resultados. 쯈u칠 modelo obtiene el mejor rendimiento? \n","\n","Por 칰ltimo, cargue el mejor modelo, prediga sobre el conjunto de test y reporte su MAE. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto?"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Modelos</th>\n","      <th>MAE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Baseline</td>\n","      <td>13308.134751</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>XGBoost</td>\n","      <td>2500.322145</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>XGBoost Constraints</td>\n","      <td>2707.911759</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>XGBoost Optuna</td>\n","      <td>1951.827763</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>XGBoost Prunning</td>\n","      <td>2029.991077</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Modelos           MAE\n","0             Baseline  13308.134751\n","1              XGBoost   2500.322145\n","2  XGBoost Constraints   2707.911759\n","3       XGBoost Optuna   1951.827763\n","4     XGBoost Prunning   2029.991077"]},"metadata":{},"output_type":"display_data"}],"source":["from IPython.display import display\n","\n","# Generando tabla resumen\n","summary = {\"Modelos\": [\"Baseline\", \"XGBoost\", \"XGBoost Constraints\", \"XGBoost Optuna\", \"XGBoost Prunning\"],\n","           \"MAE\": [mae1, mae2, mae3, best_mae, best_mae2]}\n","\n","df_sum = pd.DataFrame(summary)\n","display(df_sum)"]},{"cell_type":"markdown","metadata":{},"source":["> Comentario XD"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE del mejor modelo en el conjunto de prueba: 2000.6314546949002\n"]}],"source":["# Mejor modelo: XGBoost Optuna\n","best_model = joblib.load(\"models/best_xgb_model1.pkl\")\n","\n","# Prediciendo en test\n","best_y_pred = best_model.predict(X_test)\n","\n","# Obteniendo su MAE\n","best_mae_final = mean_absolute_error(y_test, best_y_pred)\n","print(f\"MAE del mejor modelo en el conjunto de prueba: {best_mae_final}\")"]},{"cell_type":"markdown","metadata":{"cell_id":"5c4654d12037494fbd385b4dc6bd1059","deepnote_cell_type":"markdown"},"source":["# Conclusi칩n\n","Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n","</p>"]},{"cell_type":"markdown","metadata":{"cell_id":"5025de06759f4903a26916c80323bf25","deepnote_cell_type":"markdown"},"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"f63d38450a6b464c9bb6385cf11db4d9","deepnote_persisted_session":{"createdAt":"2023-11-09T16:18:30.203Z"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":0}
