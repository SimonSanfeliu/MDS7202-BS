{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Proyecto 1 - MDS7202 Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos üìö**\n",
    "\n",
    "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n",
    "\n",
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Ignacio Meza, Gabriel Iturra\n",
    "- Auxiliar: Sebasti√°n Tinoco\n",
    "- Ayudante: Arturo Lazcano, Angelo Mu√±oz\n",
    "\n",
    "*Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir.*\n",
    "\n",
    "### Equipo:\n",
    "\n",
    "- Nicol√°s Becerra\n",
    "- Sim√≥n Sanfeli√∫\n",
    "\n",
    "\n",
    "### Link de repositorio de GitHub: https://github.com/SimonSanfeliu/MDS7202-BS/tree/Proyecto-1\n",
    "\n",
    "Fecha l√≠mite de entrega üìÜ: 27 de Octubre de 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Reglas\n",
    "\n",
    "- **Grupos de 2 personas.**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
    "- Estrictamente prohibida la copia. \n",
    "- Pueden usar cualquier material del curso que estimen conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://worldskateamerica.org/wp-content/uploads/2023/07/SANTIAGO-2023-1-768x153.jpg\" alt=\"Descripci√≥n de la imagen\">\n",
    "</div>\n",
    "\n",
    "En un Chile azotado por un profundo caos pol√≠tico-econ√≥mico y el resurgimiento de programas de televisi√≥n de dudosa calidad, todas las miradas y esperanzas son depositadas en el √©xito de un √∫nico evento: Santiago 2023. La naci√≥n necesitaba desesperadamente un respiro, y los Juegos de Santiago 2023 promet√≠an ser una luz al final del t√∫nel.\n",
    "\n",
    "El Presidente de la Rep√∫blica -conocido en las calles como Bomb√≠n-, consciente de la importancia de este evento para la revitalizaci√≥n del pa√≠s, decide convocar a usted y su equipo en calidad de expertos en an√°lisis de datos y estad√≠sticas. Con gran solemnidad, el presidente les encomienda una importante y peligrosa: liderar un proyecto que permitiera caracterizar de forma autom√°tica y eficiente los datos generados por estos magnos juegos. Para esto, el presidente le destaca que la soluci√≥n debe considerar los siguientes puntos:\n",
    "- Caracterizaci√≥n autom√°tica de los datos\n",
    "- La soluci√≥n debe ser compatible con cualquier dataset\n",
    "- Se les facilita el dataset *olimpiadas.parquet*, el cual recopila data de diferentes juegos ol√≠mpicos realizados en los √∫ltimos a√±os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creaci√≥n de `Profiler` Class (4.0 puntos)\n",
    "\n",
    "Cree la clase `Profiler`. Como m√≠nimo, esta debe tener las siguientes funcionalidades:\n",
    "\n",
    "1. El m√©todo constructor, el cual debe recibir los datos a procesar en formato `Pandas DataFrame`. Adem√°s, este m√©todo debe generar una carpeta en su directorio de trabajo con el nombre `EDA_fecha`, donde `fecha` corresponda a la fecha de ejecuci√≥n en formato `DD-MM-YYYY`.\n",
    "\n",
    "2. El m√©todo `summarize`, el cual debe caracterizar las variables del Dataset. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    - Reportar el tipo de variable\n",
    "    - Reportar el n√∫mero y/o porcentaje de valores √∫nicos de la variable\n",
    "    - Reportar el n√∫mero y/o porcentaje de valores nulos\n",
    "    - Si la variables es num√©rica:\n",
    "        - Reportar el n√∫mero y/o porcentaje de valores cero, negativos y outliers\n",
    "        - Reportar estad√≠stica descriptiva como el valor m√≠nimo, m√°ximo, promedio y los percentiles 25, 50, 75 y 100\n",
    "   - Levantar una alerta en caso de encontrar alguna anomal√≠a fuera de lo com√∫n (el criterio debe ser ajustable por el usuario)\n",
    "   - Guardar sus resultados en el directorio `EDA_fecha/summary.txt`. El archivo debe separar de forma clara y ordenada los resultados de cada punto.\n",
    "\n",
    "3. El m√©todo `plot_vars`, el cual debe graficar la distribuci√≥n e interraciones de las variables del Dataset. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/plots`\n",
    "    - Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    - Para las variables num√©ricas:\n",
    "        - Genere un gr√°fico de distribuci√≥n de densidad\n",
    "        - Grafique la correlaci√≥n entre las variables\n",
    "    - Para las variables categ√≥ricas:\n",
    "        - Genere un histograma de las top N categor√≠as (N debe ser un par√°metro ajustable)\n",
    "        - Grafique el coeficiente V de Cramer entre las variables\n",
    "    - Guardar cada gr√°fico generado en la carpeta `EDA_fecha/plots` en formato `.pdf` y bajo el naming `variable.pdf`, donde `variable` es el nombre de la variable de inter√©s\n",
    "    \n",
    "4. El m√©todo `clean_data`, el cual debe limpiar los datos para que luego puedan ser procesados. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/clean_data`\n",
    "    - Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    - Drop de valores duplicados\n",
    "    - Implementar como m√≠nimo 2 t√©cnicas para tratar los valores nulos, como:\n",
    "        - Drop de valores nulos\n",
    "        - Imputar valores nulos con alguna t√©cnica de imputaci√≥n\n",
    "        - Funcionalidad para escoger entre una t√©cnica y la otra.\n",
    "    - Una de las columnas del dataframe presenta datos *no at√≥micos*. Separe dicha columna en las columnas que la compongan.\n",
    "        - Hint: ¬øQu√© caracteres permiten separar una columna de otra?\n",
    "        - Para las pruebas con el dataset nuevo, puede esperar que exista al menos una columna con este tipo de problema. Asuma que los separadores ser√°n los mismos, aunque el n√∫mero de columnas a separar puede ser distinto.\n",
    "    - Deber√≠an usar `FunctionTransformer`.\n",
    "    - Guardar los datos procesados en formato `.csv` en el path `EDA_fecha/clean_data/data.csv`\n",
    "\n",
    "5. El m√©todo `scale`, el cual debe preparar adecuadamente los datos para luego ser consumidos por alg√∫n tipo de algoritmo. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/scale`\n",
    "    - Procesar de forma adecuada los datos num√©ricos y categ√≥ricos:\n",
    "        - Su m√©todo debe recibir las t√©cnicas de escalamiento como argumento de entrada (utilizar solo t√©cnicas compatibles con el framework de `sklearn`)\n",
    "        - Para los atributos num√©ricos, se transforme los datos con un escalador logar√≠tmico y un `MinMaxScaler`\n",
    "        - Asuma que no existen datos ordinales en su dataset\n",
    "    - Guardar todo este procesamiento en un `ColumnTransformer`.\n",
    "    - Guardar los datos limpios y transformados en formato `.csv` en el path `EDA_fecha/process/scaled_features.csv`\n",
    "\n",
    "6. El m√©todo `make_clusters`, el cual debe generar clusters de los datos usando alg√∫n algoritmo de clusterizaci√≥n. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/clusters`\n",
    "    - Generar un estudio del codo donde se√±ale la cantidad de clusters optimos para el desarrollo.\n",
    "    - Su m√©todo debe recibir el algoritmo de clustering como argumento de entrada (utilizar solo algoritmos compatibles con el framework de `sklearn`).\n",
    "    - No olvide pre procesar adecuadamente los datos antes de implementar la t√©cnica de clustering. \n",
    "    - En este punto es espera que generen un `Pipeline` de sklearn. Adem√°s, su m√©todo deber√≠a usar lo construido en los puntos 4 y 5. \n",
    "    - Su m√©todo debe ser capaz de funcionar a partir de datos crudos (se descontar√° puntaje de lo contrario).\n",
    "    - Una vez generado los clusters, proyecte los datos a 2 dimensiones usando su t√©cnica de reducci√≥n de dimensionalidad favorita y grafique los resultados coloreando por cluster.\n",
    "    - Guardar los datos con su respectivo cluster en formato `.csv` en el path `EDA_fecha/clusters/data_clusters.csv`. Guarde tambi√©n los gr√°ficos generados en el mismo path.\n",
    "\n",
    "7. El m√©todo `detect_anomalies`, el cual debe detectar anomal√≠as en los datos. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "\n",
    "    - Crear la carpeta `EDA_fecha/anomalies`\n",
    "    - Implementar alguna t√©cnica de detecci√≥n de anomal√≠as.\n",
    "    - Al igual que el punto anterior, su m√©todo debe considerar los siguientes puntos:\n",
    "        - No olvide pre procesar de forma adecuada los datos antes de implementar la t√©cnica de detecci√≥n de anomal√≠a. \n",
    "        - En este punto es espera que generen un `Pipeline` de sklearn. Adem√°s, su m√©todo deber√≠a usar lo construido en los puntos 4 y 5. \n",
    "        - Su m√©todo debe ser capaz de funcionar a partir de datos crudos (se descontar√° puntaje de lo contrario).\n",
    "        - Su m√©todo debe recibir el algoritmo como argumento de entrada\n",
    "        - Una vez generado las etiquetas, proyecte los datos a 2 dimensiones y grafique los resultados coloreando por las etiquetas predichas por el detector de anomal√≠as\n",
    "    - Guardar los datos con su respectiva etiqueta en formato `.csv` en el path `EDA_fecha/anomalies/data_anomalies.csv`. Guarde tambi√©n los gr√°ficos generados en el mismo path.\n",
    "\n",
    "8. El m√©todo `profile`, el cual debe ejecutar todos los m√©todos anteriores.\n",
    "\n",
    "9. Crear el m√©todo `clearGarbage` para eliminar las carpetas/archivos creados/as por la clase `Profiler`.\n",
    "\n",
    "Algunas consideraciones generales:\n",
    "- Su clase ser√° testeada con datos tabulares diferentes a los provistos. No desarrollen c√≥digo *hardcodeado*: su clase debe ser capaz de funcionar para **cualquier** dataset. \n",
    "- Aplique todo su conocimiento sobre buenas pr√°cticas de programaci√≥n: se evaluar√° que su c√≥digo sea limpio y ordenado.\n",
    "- Recuerden documentar cada una de las funcionalidades que implementen.\n",
    "- Recuerden adjuntar sus `requirements.txt` junto a su entrega de proyecto. **El c√≥digo que no se pueda ejecutar por imcompatibilidades de librer√≠as no ser√° corregido.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as necesarias para el proyecto\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from scipy import stats\n",
    "from dfcorrs import cramersvcorr\n",
    "import seaborn as sns\n",
    "\n",
    "# Librer√°s para plotear\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Profiler():\n",
    "    \"\"\"\n",
    "    Agregar docstring\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Agregar docstring\n",
    "        \"\"\"\n",
    "        assert type(df) == pd.DataFrame\n",
    "        self.df = df\n",
    "        self.eda_path = f\"EDA_{datetime.now().strftime('%d-%m-%Y')}\"\n",
    "        if not os.path.exists(self.eda_path):\n",
    "            os.mkdir(self.eda_path)\n",
    "\n",
    "    def summarize(self, columns, anomalies):\n",
    "        \"\"\"\n",
    "        Agregar docstring\n",
    "        \"\"\"\n",
    "        # Viendo los tipos\n",
    "        assert type(columns) == str or type(columns) == list\n",
    "        assert type(anomalies) == list\n",
    "\n",
    "        if type(columns) == str:\n",
    "            serie_in = self.df[columns]\n",
    "            serie = serie_in.copy()\n",
    "\n",
    "            profile = pd.Series(dtype='object')\n",
    "            profile[\"Name\"] = columns\n",
    "            profile[\"Type\"] = serie.dtype\n",
    "            profile = pd.concat([profile, serie.describe(percentiles=[.25, .5, .75, 1], datetime_is_numeric=True)])\n",
    "\n",
    "            if is_numeric_dtype(serie):\n",
    "                profile[\"Negative\"] = (serie < 0).sum()\n",
    "                profile[\"Negative (%)\"] = (\n",
    "                    str(round((serie < 0).sum() / len(serie) * 100, 2)) + \" %\"\n",
    "                )\n",
    "                profile[\"Zeros\"] = (serie == 0).sum()\n",
    "                profile[\"Zeros (%)\"] = (\n",
    "                    str(round((serie == 0).sum() / len(serie) * 100, 2)) + \" %\"\n",
    "                )\n",
    "                only_outliers = serie.loc[(np.abs(stats.zscore(serie)) >= 3)]\n",
    "                profile[\"Outliers\"] = only_outliers.shape[0]\n",
    "                profile[\"Outliers (%)\"] = (\n",
    "                    str(round(only_outliers.shape[0] / len(serie) * 100, 2)) + \" %\"\n",
    "                )\n",
    "\n",
    "            profile[\"Missing cells\"] = serie.isnull().sum()\n",
    "            profile[\"Missing cells (%)\"] = (\n",
    "                str(round(serie.isnull().sum() / len(serie) * 100, 2)) + \" %\"\n",
    "            )\n",
    "\n",
    "            profile = profile.rename(\n",
    "                index={\n",
    "                    \"count\": \"Number of observations\",\n",
    "                    \"mean\": \"Mean\",\n",
    "                    \"std\": \"Std\",\n",
    "                    \"min\": \"Min\",\n",
    "                    \"max\": \"Max\",\n",
    "                    \"unique\": \"Unique\",\n",
    "                    \"top\": \"Top\",\n",
    "                    \"freq\": \"Freq\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Pasando la data a un txt\n",
    "            txt = \"Reporte de variable \\n\\n\" + profile.to_string()\n",
    "            new_file = open(f\"{self.eda_path}/summary.txt\", \"w+\")\n",
    "            new_file.write(txt)\n",
    "            new_file.close()\n",
    "\n",
    "        else:\n",
    "            txt = \"Reporte de variables \\n\\n\"\n",
    "            for c in columns:\n",
    "                serie_in = self.df[c]\n",
    "                serie = serie_in.copy()\n",
    "\n",
    "                profile = pd.Series(dtype='object')\n",
    "                profile[\"Name\"] = c\n",
    "                profile[\"Type\"] = serie.dtype\n",
    "                profile = pd.concat([profile, serie.describe(percentiles=[.25, .5, .75, 1], datetime_is_numeric=True)])\n",
    "\n",
    "                if is_numeric_dtype(serie):\n",
    "                    profile[\"Negative\"] = (serie < 0).sum()\n",
    "                    profile[\"Negative (%)\"] = (\n",
    "                        str(round((serie < 0).sum() / len(serie) * 100, 2)) + \" %\"\n",
    "                    )\n",
    "                    profile[\"Zeros\"] = (serie == 0).sum()\n",
    "                    profile[\"Zeros (%)\"] = (\n",
    "                        str(round((serie == 0).sum() / len(serie) * 100, 2)) + \" %\"\n",
    "                    )\n",
    "                    only_outliers = serie.loc[(np.abs(stats.zscore(serie)) > 3)]\n",
    "                    profile[\"Outliers\"] = only_outliers.shape[0]\n",
    "                    profile[\"Outliers (%)\"] = (\n",
    "                        str(round(only_outliers.shape[0] / len(serie) * 100, 2)) + \" %\"\n",
    "                    )\n",
    "\n",
    "                profile[\"Missing cells\"] = serie.isnull().sum()\n",
    "                profile[\"Missing cells (%)\"] = (\n",
    "                    str(round(serie.isnull().sum() / len(serie) * 100, 2)) + \" %\"\n",
    "                )\n",
    "\n",
    "                profile = profile.rename(\n",
    "                    index={\n",
    "                        \"count\": \"Number of observations\",\n",
    "                        \"mean\": \"Mean\",\n",
    "                        \"std\": \"Std\",\n",
    "                        \"min\": \"Min\",\n",
    "                        \"max\": \"Max\",\n",
    "                        \"unique\": \"Unique\",\n",
    "                        \"top\": \"Top\",\n",
    "                        \"freq\": \"Freq\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # Guardando la data a un solo string\n",
    "                txt += profile.to_string() + \"\\n\\n\"\n",
    "\n",
    "            # Pasando la data a un txt\n",
    "            new_file = open(f\"{self.eda_path}/summary.txt\", \"w\")\n",
    "            new_file.write(txt)\n",
    "            new_file.close()\n",
    "\n",
    "    def plot_vars(self, columns, N=10):\n",
    "        \"\"\"\n",
    "        Agregar docstring\n",
    "        \"\"\"\n",
    "        # Viendo los tipos\n",
    "        assert type(columns) == str or type(columns) == list\n",
    "        assert type(N) == int\n",
    "\n",
    "        # Generando la carpeta de plots\n",
    "        plot_path = self.eda_path + \"/plots\"\n",
    "        if not os.path.exists(plot_path):\n",
    "            os.mkdir(plot_path)\n",
    "\n",
    "        if type(columns) == str:\n",
    "            serie_in = self.df[columns]\n",
    "            serie = serie_in.copy()\n",
    "\n",
    "            if is_numeric_dtype(serie):\n",
    "                ## Variables num√©ricas\n",
    "                # Gr√°fico de distribuci√≥n\n",
    "                fig = ff.create_distplot([list(serie.values)], [serie.name], show_hist=False, show_rug=False)\n",
    "                fig.update_layout(title_text=f\"Distribuci√≥n de {serie.name}\")\n",
    "                fig.write_image(plot_path+f\"/{serie.name}_dist.pdf\")\n",
    "\n",
    "                # Matriz de correlaci√≥n entre variables num√©ricas\n",
    "                corr = self.df.corr(numeric_only=True)\n",
    "                sns.heatmap(corr, annot=True).set(title=\"Matriz de correlaci√≥n de variables num√©ricas\")\n",
    "                plt.savefig(plot_path+\"/corrMatrix.pdf\")\n",
    "            else:\n",
    "                ## Variables categ√≥ricas\n",
    "                # Histograma de N categor√≠as m√°s comunes\n",
    "                count = (\n",
    "                    serie.value_counts()[0:N]\n",
    "                    .reset_index()\n",
    "                    .rename(columns = {serie.name: 'Count'})\n",
    "                )\n",
    "                fig = px.bar(\n",
    "                    x=count['index'].astype(str),\n",
    "                    y=count[\"Count\"],\n",
    "                    title=f\"{N} categor√≠as m√°s comunes {serie.name}\",\n",
    "                )\n",
    "                fig.write_image(plot_path+f\"/{serie.name}_nCategories.pdf\")\n",
    "\n",
    "                # Obteniendo la matriz de correlaci√≥n de la V de Cramer\n",
    "                htmp = cramersvcorr.cal(self.df, plot_htmp=True)\n",
    "                htmp.write_image(plot_path+\"/cramerVCorrMap.pdf\")\n",
    "\n",
    "        else:\n",
    "            numeric = 0\n",
    "            categorical = 0\n",
    "            for c in columns:\n",
    "                serie_in = self.df[c]\n",
    "                serie = serie_in.copy()\n",
    "\n",
    "                if is_numeric_dtype(serie):\n",
    "                    numeric == 1\n",
    "                    ## Variables num√©ricas\n",
    "                    # Gr√°fico de distribuci√≥n\n",
    "                    fig = ff.create_distplot([list(serie.values)], [serie.name], show_hist=False, show_rug=False)\n",
    "                    fig.update_layout(title_text=f\"Distribuci√≥n de {serie.name}\")\n",
    "                    fig.write_image(plot_path+f\"/{serie.name}_dist.pdf\")\n",
    "                else:\n",
    "                    categorical == 1\n",
    "                    ## Variables categ√≥ricas\n",
    "                    # Histograma de N categor√≠as m√°s comunes\n",
    "                    count = (\n",
    "                        serie.value_counts()[0:N]\n",
    "                        .reset_index()\n",
    "                        .rename(columns = {serie.name: 'Count'})\n",
    "                    )\n",
    "                    fig = px.bar(\n",
    "                        x=count['index'].astype(str),\n",
    "                        y=count[\"Count\"],\n",
    "                        title=f\"{N} categor√≠as m√°s comunes {serie.name}\",\n",
    "                    )\n",
    "                    fig.write_image(plot_path+f\"/{serie.name}_nCategories.pdf\")\n",
    "\n",
    "            # S√≥lo son necesarios un gr√°fico de correlaci√≥n num√©rica y/o categ√≥rica,\n",
    "            # seg√∫n corresponda\n",
    "            if numeric == 1:\n",
    "                # Matriz de correlaci√≥n entre variables num√©ricas\n",
    "                corr = self.df.corr(numeric_only=True)\n",
    "                sns.heatmap(corr, annot=True).set(title=\"Matriz de correlaci√≥n de variables num√©ricas\")\n",
    "                plt.savefig(plot_path+\"/corrMatrix.pdf\")\n",
    "            if categorical == 1:\n",
    "                # Obteniendo la matriz de correlaci√≥n de la V de Cramer\n",
    "                htmp = cramersvcorr.cal(self.df, plot_htmp=True)\n",
    "                htmp.write_image(plot_path+\"/cramerVCorrMap.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "negative dimensions are not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sanfe\\Documents\\M√≠o\\Trabajos\\Universidad\\El√©ctrica\\Semestre 7\\Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos\\MDS7202-BS\\Proyecto1\\Proyecto1_Becerra_Sanfeli√∫.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sanfe/Documents/M%C3%ADo/Trabajos/Universidad/El%C3%A9ctrica/Semestre%207/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica%20para%20Ciencia%20de%20Datos/MDS7202-BS/Proyecto1/Proyecto1_Becerra_Sanfeli%C3%BA.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39;49mcrosstab(df[\u001b[39m\"\u001b[39;49m\u001b[39mage-height-weight\u001b[39;49m\u001b[39m\"\u001b[39;49m], df[\u001b[39m\"\u001b[39;49m\u001b[39mName\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\pivot.py:691\u001b[0m, in \u001b[0;36mcrosstab\u001b[1;34m(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)\u001b[0m\n\u001b[0;32m    688\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39m__dummy__\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m values\n\u001b[0;32m    689\u001b[0m     kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39maggfunc\u001b[39m\u001b[39m\"\u001b[39m: aggfunc}\n\u001b[1;32m--> 691\u001b[0m table \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mpivot_table(\n\u001b[0;32m    692\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m__dummy__\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    693\u001b[0m     index\u001b[39m=\u001b[39munique_rownames,\n\u001b[0;32m    694\u001b[0m     columns\u001b[39m=\u001b[39munique_colnames,\n\u001b[0;32m    695\u001b[0m     margins\u001b[39m=\u001b[39mmargins,\n\u001b[0;32m    696\u001b[0m     margins_name\u001b[39m=\u001b[39mmargins_name,\n\u001b[0;32m    697\u001b[0m     dropna\u001b[39m=\u001b[39mdropna,\n\u001b[0;32m    698\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    699\u001b[0m )\n\u001b[0;32m    701\u001b[0m \u001b[39m# Post-process\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[39mif\u001b[39;00m normalize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:8731\u001b[0m, in \u001b[0;36mDataFrame.pivot_table\u001b[1;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m   8714\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   8715\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   8716\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpivot_table\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8727\u001b[0m     sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   8728\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   8729\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpivot\u001b[39;00m \u001b[39mimport\u001b[39;00m pivot_table\n\u001b[1;32m-> 8731\u001b[0m     \u001b[39mreturn\u001b[39;00m pivot_table(\n\u001b[0;32m   8732\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   8733\u001b[0m         values\u001b[39m=\u001b[39;49mvalues,\n\u001b[0;32m   8734\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   8735\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   8736\u001b[0m         aggfunc\u001b[39m=\u001b[39;49maggfunc,\n\u001b[0;32m   8737\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[0;32m   8738\u001b[0m         margins\u001b[39m=\u001b[39;49mmargins,\n\u001b[0;32m   8739\u001b[0m         dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   8740\u001b[0m         margins_name\u001b[39m=\u001b[39;49mmargins_name,\n\u001b[0;32m   8741\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   8742\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   8743\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\pivot.py:97\u001b[0m, in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m     94\u001b[0m     table \u001b[39m=\u001b[39m concat(pieces, keys\u001b[39m=\u001b[39mkeys, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m table \u001b[39m=\u001b[39m __internal_pivot_table(\n\u001b[0;32m     98\u001b[0m     data,\n\u001b[0;32m     99\u001b[0m     values,\n\u001b[0;32m    100\u001b[0m     index,\n\u001b[0;32m    101\u001b[0m     columns,\n\u001b[0;32m    102\u001b[0m     aggfunc,\n\u001b[0;32m    103\u001b[0m     fill_value,\n\u001b[0;32m    104\u001b[0m     margins,\n\u001b[0;32m    105\u001b[0m     dropna,\n\u001b[0;32m    106\u001b[0m     margins_name,\n\u001b[0;32m    107\u001b[0m     observed,\n\u001b[0;32m    108\u001b[0m     sort,\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\pivot.py:219\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m             to_unstack\u001b[39m.\u001b[39mappend(name)\n\u001b[1;32m--> 219\u001b[0m     table \u001b[39m=\u001b[39m agged\u001b[39m.\u001b[39;49munstack(to_unstack)\n\u001b[0;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dropna:\n\u001b[0;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(table\u001b[39m.\u001b[39mindex, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:9112\u001b[0m, in \u001b[0;36mDataFrame.unstack\u001b[1;34m(self, level, fill_value)\u001b[0m\n\u001b[0;32m   9050\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9051\u001b[0m \u001b[39mPivot a level of the (necessarily hierarchical) index labels.\u001b[39;00m\n\u001b[0;32m   9052\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9108\u001b[0m \u001b[39mdtype: float64\u001b[39;00m\n\u001b[0;32m   9109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9110\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m \u001b[39mimport\u001b[39;00m unstack\n\u001b[1;32m-> 9112\u001b[0m result \u001b[39m=\u001b[39m unstack(\u001b[39mself\u001b[39;49m, level, fill_value)\n\u001b[0;32m   9114\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munstack\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\reshape.py:476\u001b[0m, in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, DataFrame):\n\u001b[0;32m    475\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m--> 476\u001b[0m         \u001b[39mreturn\u001b[39;00m _unstack_frame(obj, level, fill_value\u001b[39m=\u001b[39;49mfill_value)\n\u001b[0;32m    477\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mstack(dropna\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\reshape.py:499\u001b[0m, in \u001b[0;36m_unstack_frame\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unstack_frame\u001b[39m(obj: DataFrame, level, fill_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mindex, MultiIndex)  \u001b[39m# checked by caller\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m     unstacker \u001b[39m=\u001b[39m _Unstacker(obj\u001b[39m.\u001b[39;49mindex, level\u001b[39m=\u001b[39;49mlevel, constructor\u001b[39m=\u001b[39;49mobj\u001b[39m.\u001b[39;49m_constructor)\n\u001b[0;32m    501\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m obj\u001b[39m.\u001b[39m_can_fast_transpose:\n\u001b[0;32m    502\u001b[0m         mgr \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39munstack(unstacker, fill_value\u001b[39m=\u001b[39mfill_value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\reshape.py:137\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[1;34m(self, index, level, constructor)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m num_cells \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax:\n\u001b[0;32m    130\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    131\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe following operation may generate \u001b[39m\u001b[39m{\u001b[39;00mnum_cells\u001b[39m}\u001b[39;00m\u001b[39m cells \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39min the resulting pandas object.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    133\u001b[0m         PerformanceWarning,\n\u001b[0;32m    134\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    135\u001b[0m     )\n\u001b[1;32m--> 137\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_selectors()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\reshape.py:185\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_shape \u001b[39m=\u001b[39m ngroups, stride\n\u001b[0;32m    184\u001b[0m selector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msorted_labels[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m stride \u001b[39m*\u001b[39m comp_index \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlift\n\u001b[1;32m--> 185\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros(np\u001b[39m.\u001b[39;49mprod(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_shape), dtype\u001b[39m=\u001b[39;49m\u001b[39mbool\u001b[39;49m)\n\u001b[0;32m    186\u001b[0m mask\u001b[39m.\u001b[39mput(selector, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39msum() \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex):\n",
      "\u001b[1;31mValueError\u001b[0m: negative dimensions are not allowed"
     ]
    }
   ],
   "source": [
    "pd.crosstab(df[\"age-height-weight\"], df[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name, Name\n",
      "Name, Sex\n",
      "Name, Team\n",
      "Name, NOC\n",
      "Name, Games\n",
      "Name, Season\n",
      "Name, City\n",
      "Name, Sport\n",
      "Name, Event\n",
      "Name, Medal\n",
      "Name, age-height-weight\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "negative dimensions are not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sanfe\\Documents\\M√≠o\\Trabajos\\Universidad\\El√©ctrica\\Semestre 7\\Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos\\MDS7202-BS\\Proyecto1\\Proyecto1_Becerra_Sanfeli√∫.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanfe/Documents/M%C3%ADo/Trabajos/Universidad/El%C3%A9ctrica/Semestre%207/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica%20para%20Ciencia%20de%20Datos/MDS7202-BS/Proyecto1/Proyecto1_Becerra_Sanfeli%C3%BA.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m prof \u001b[39m=\u001b[39m Profiler(df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanfe/Documents/M%C3%ADo/Trabajos/Universidad/El%C3%A9ctrica/Semestre%207/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica%20para%20Ciencia%20de%20Datos/MDS7202-BS/Proyecto1/Proyecto1_Becerra_Sanfeli%C3%BA.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m prof\u001b[39m.\u001b[39msummarize([\u001b[39m\"\u001b[39m\u001b[39mName\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m\"\u001b[39m], [])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sanfe/Documents/M%C3%ADo/Trabajos/Universidad/El%C3%A9ctrica/Semestre%207/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica%20para%20Ciencia%20de%20Datos/MDS7202-BS/Proyecto1/Proyecto1_Becerra_Sanfeli%C3%BA.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m prof\u001b[39m.\u001b[39;49mplot_vars(\u001b[39m\"\u001b[39;49m\u001b[39mName\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\sanfe\\Documents\\M√≠o\\Trabajos\\Universidad\\El√©ctrica\\Semestre 7\\Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos\\MDS7202-BS\\Proyecto1\\Proyecto1_Becerra_Sanfeli√∫.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sanfe/Documents/M%C3%ADo/Trabajos/Universidad/El%C3%A9ctrica/Semestre%207/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica%20para%20Ciencia%20de%20Datos/MDS7202-BS/Proyecto1/Proyecto1_Becerra_Sanfeli%C3%BA.ipynb#X10sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m fig\u001b[39m.\u001b[39mwrite_image(plot_path\u001b[39m+\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mserie\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_nCategories.pdf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sanfe/Documents/M%C3%ADo/Trabajos/Universidad/El%C3%A9ctrica/Semestre%207/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica%20para%20Ciencia%20de%20Datos/MDS7202-BS/Proyecto1/Proyecto1_Becerra_Sanfeli%C3%BA.ipynb#X10sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m \u001b[39m# Obteniendo la matriz de correlaci√≥n de la V de Cramer\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/sanfe/Documents/M%C3%ADo/Trabajos/Universidad/El%C3%A9ctrica/Semestre%207/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica%20para%20Ciencia%20de%20Datos/MDS7202-BS/Proyecto1/Proyecto1_Becerra_Sanfeli%C3%BA.ipynb#X10sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m htmp \u001b[39m=\u001b[39m cramersvcorr\u001b[39m.\u001b[39;49mcal(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf, plot_htmp\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sanfe/Documents/M%C3%ADo/Trabajos/Universidad/El%C3%A9ctrica/Semestre%207/Laboratorio%20de%20Programaci%C3%B3n%20Cient%C3%ADfica%20para%20Ciencia%20de%20Datos/MDS7202-BS/Proyecto1/Proyecto1_Becerra_Sanfeli%C3%BA.ipynb#X10sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m htmp\u001b[39m.\u001b[39mwrite_image(plot_path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/cramerVCorrMap.pdf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sanfe\\Documents\\M√≠o\\Trabajos\\Universidad\\El√©ctrica\\Semestre 7\\Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos\\MDS7202-BS\\Proyecto1\\dfcorrs\\cramersvcorr.py:50\u001b[0m, in \u001b[0;36mcal\u001b[1;34m(data, add_cols, rem_cols, plot_htmp)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m     49\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m             coef\u001b[39m=\u001b[39m cramers_v(data[i], data[j])\n\u001b[0;32m     51\u001b[0m             coef_scores\u001b[39m.\u001b[39mappend(coef)\n\u001b[0;32m     53\u001b[0m reshape_val\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39msqrt(\u001b[39mlen\u001b[39m(coef_scores)))\n",
      "File \u001b[1;32mc:\\Users\\sanfe\\Documents\\M√≠o\\Trabajos\\Universidad\\El√©ctrica\\Semestre 7\\Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos\\MDS7202-BS\\Proyecto1\\dfcorrs\\cramersvcorr.py:12\u001b[0m, in \u001b[0;36mcramers_v\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcramers_v\u001b[39m(x, y):\n\u001b[1;32m---> 12\u001b[0m     confusion_matrix \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mcrosstab(x,y)\n\u001b[0;32m     13\u001b[0m     chi2 \u001b[39m=\u001b[39m ss\u001b[39m.\u001b[39mchi2_contingency(confusion_matrix)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m     n \u001b[39m=\u001b[39m confusion_matrix\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39msum()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\pivot.py:691\u001b[0m, in \u001b[0;36mcrosstab\u001b[1;34m(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)\u001b[0m\n\u001b[0;32m    688\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39m__dummy__\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m values\n\u001b[0;32m    689\u001b[0m     kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39maggfunc\u001b[39m\u001b[39m\"\u001b[39m: aggfunc}\n\u001b[1;32m--> 691\u001b[0m table \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mpivot_table(\n\u001b[0;32m    692\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m__dummy__\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    693\u001b[0m     index\u001b[39m=\u001b[39munique_rownames,\n\u001b[0;32m    694\u001b[0m     columns\u001b[39m=\u001b[39munique_colnames,\n\u001b[0;32m    695\u001b[0m     margins\u001b[39m=\u001b[39mmargins,\n\u001b[0;32m    696\u001b[0m     margins_name\u001b[39m=\u001b[39mmargins_name,\n\u001b[0;32m    697\u001b[0m     dropna\u001b[39m=\u001b[39mdropna,\n\u001b[0;32m    698\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    699\u001b[0m )\n\u001b[0;32m    701\u001b[0m \u001b[39m# Post-process\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[39mif\u001b[39;00m normalize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:8731\u001b[0m, in \u001b[0;36mDataFrame.pivot_table\u001b[1;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m   8714\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   8715\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   8716\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpivot_table\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8727\u001b[0m     sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   8728\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   8729\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpivot\u001b[39;00m \u001b[39mimport\u001b[39;00m pivot_table\n\u001b[1;32m-> 8731\u001b[0m     \u001b[39mreturn\u001b[39;00m pivot_table(\n\u001b[0;32m   8732\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   8733\u001b[0m         values\u001b[39m=\u001b[39;49mvalues,\n\u001b[0;32m   8734\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   8735\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   8736\u001b[0m         aggfunc\u001b[39m=\u001b[39;49maggfunc,\n\u001b[0;32m   8737\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[0;32m   8738\u001b[0m         margins\u001b[39m=\u001b[39;49mmargins,\n\u001b[0;32m   8739\u001b[0m         dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   8740\u001b[0m         margins_name\u001b[39m=\u001b[39;49mmargins_name,\n\u001b[0;32m   8741\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   8742\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   8743\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\pivot.py:97\u001b[0m, in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m     94\u001b[0m     table \u001b[39m=\u001b[39m concat(pieces, keys\u001b[39m=\u001b[39mkeys, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m table \u001b[39m=\u001b[39m __internal_pivot_table(\n\u001b[0;32m     98\u001b[0m     data,\n\u001b[0;32m     99\u001b[0m     values,\n\u001b[0;32m    100\u001b[0m     index,\n\u001b[0;32m    101\u001b[0m     columns,\n\u001b[0;32m    102\u001b[0m     aggfunc,\n\u001b[0;32m    103\u001b[0m     fill_value,\n\u001b[0;32m    104\u001b[0m     margins,\n\u001b[0;32m    105\u001b[0m     dropna,\n\u001b[0;32m    106\u001b[0m     margins_name,\n\u001b[0;32m    107\u001b[0m     observed,\n\u001b[0;32m    108\u001b[0m     sort,\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\pivot.py:219\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m             to_unstack\u001b[39m.\u001b[39mappend(name)\n\u001b[1;32m--> 219\u001b[0m     table \u001b[39m=\u001b[39m agged\u001b[39m.\u001b[39;49munstack(to_unstack)\n\u001b[0;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dropna:\n\u001b[0;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(table\u001b[39m.\u001b[39mindex, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:9112\u001b[0m, in \u001b[0;36mDataFrame.unstack\u001b[1;34m(self, level, fill_value)\u001b[0m\n\u001b[0;32m   9050\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9051\u001b[0m \u001b[39mPivot a level of the (necessarily hierarchical) index labels.\u001b[39;00m\n\u001b[0;32m   9052\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9108\u001b[0m \u001b[39mdtype: float64\u001b[39;00m\n\u001b[0;32m   9109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9110\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m \u001b[39mimport\u001b[39;00m unstack\n\u001b[1;32m-> 9112\u001b[0m result \u001b[39m=\u001b[39m unstack(\u001b[39mself\u001b[39;49m, level, fill_value)\n\u001b[0;32m   9114\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munstack\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\reshape.py:476\u001b[0m, in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, DataFrame):\n\u001b[0;32m    475\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m--> 476\u001b[0m         \u001b[39mreturn\u001b[39;00m _unstack_frame(obj, level, fill_value\u001b[39m=\u001b[39;49mfill_value)\n\u001b[0;32m    477\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mstack(dropna\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\reshape.py:499\u001b[0m, in \u001b[0;36m_unstack_frame\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unstack_frame\u001b[39m(obj: DataFrame, level, fill_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mindex, MultiIndex)  \u001b[39m# checked by caller\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m     unstacker \u001b[39m=\u001b[39m _Unstacker(obj\u001b[39m.\u001b[39;49mindex, level\u001b[39m=\u001b[39;49mlevel, constructor\u001b[39m=\u001b[39;49mobj\u001b[39m.\u001b[39;49m_constructor)\n\u001b[0;32m    501\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m obj\u001b[39m.\u001b[39m_can_fast_transpose:\n\u001b[0;32m    502\u001b[0m         mgr \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39munstack(unstacker, fill_value\u001b[39m=\u001b[39mfill_value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\reshape.py:137\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[1;34m(self, index, level, constructor)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m num_cells \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax:\n\u001b[0;32m    130\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    131\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe following operation may generate \u001b[39m\u001b[39m{\u001b[39;00mnum_cells\u001b[39m}\u001b[39;00m\u001b[39m cells \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39min the resulting pandas object.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    133\u001b[0m         PerformanceWarning,\n\u001b[0;32m    134\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    135\u001b[0m     )\n\u001b[1;32m--> 137\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_selectors()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\reshape.py:185\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_shape \u001b[39m=\u001b[39m ngroups, stride\n\u001b[0;32m    184\u001b[0m selector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msorted_labels[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m stride \u001b[39m*\u001b[39m comp_index \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlift\n\u001b[1;32m--> 185\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros(np\u001b[39m.\u001b[39;49mprod(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_shape), dtype\u001b[39m=\u001b[39;49m\u001b[39mbool\u001b[39;49m)\n\u001b[0;32m    186\u001b[0m mask\u001b[39m.\u001b[39mput(selector, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39msum() \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex):\n",
      "\u001b[1;31mValueError\u001b[0m: negative dimensions are not allowed"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"olimpiadas.parquet\")\n",
    "prof = Profiler(df)\n",
    "prof.summarize([\"Name\", \"Year\"], [])\n",
    "prof.plot_vars(\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Caracterizar datos de Olimpiadas (2.0 puntos)\n",
    "\n",
    "A partir de la clase que hemos desarrollado previamente, procederemos a realizar un an√°lisis exhaustivo de los datos proporcionados en el enunciado. Este an√°lisis se presentar√° en forma de un informe contenido en el mismo Jupyter Notebook y abordar√° los siguientes puntos:\n",
    "\n",
    "1. Introducci√≥n\n",
    "    - Se proporcionar√° una breve descripci√≥n del problema que estamos abordando y se explicar√° la metodolog√≠a que se seguir√°.\n",
    "\n",
    "Elaborar una breve introducci√≥n con todo lo necesario para entender qu√© realizar√°n durante su proyecto. La idea es que describan de manera formal el proyecto con sus propias palabras y logren describir algunos aspectos b√°sicos tanto del dataset como del an√°lisis a realizar sobre los datos.\n",
    "\n",
    "Por lo anterior, en esta secci√≥n ustedes deber√°n ser capaces de:\n",
    "\n",
    "- Describir la tarea asociada al dataset.\n",
    "- Describir brevemente los datos de entrada que les provee el problema.\n",
    "- Plantear hip√≥tesis de c√≥mo podr√≠an abordar el problema.\n",
    "\n",
    "2. An√°lisis del EDA (An√°lisis Exploratorio de Datos)\n",
    "    - Se discutir√°n las observaciones y conclusiones obtenidas acerca de los datos proporcionados. A lo largo de su respuesta, debe responder preguntas como:\n",
    "        - ¬øComo se comportan las variables num√©ricas? ¬øy las categ√≥ricas?\n",
    "        - ¬øExisten valores nulos en el dataset? ¬øEn qu√© columnas? ¬øCuantos?\n",
    "        - ¬øCu√°les son las categor√≠as y frecuencias de las variables categ√≥ricas?\n",
    "        - ¬øExisten datos duplicados en el conjunto?\n",
    "        - ¬øExisten relaciones o patrones visuales entre las variables?\n",
    "        - ¬øExisten anomal√≠as notables o preocupantes en los datos?\n",
    "3. Creaci√≥n de Clusters y Anomal√≠as\n",
    "    - Se justificar√° la elecci√≥n de los algoritmos a utilizar y sus hiperpar√°metros. En el caso de clustering, justifique adem√°s el n√∫mero de clusters.\n",
    "    \n",
    "4. An√°lisis de Resultados\n",
    "    - Se examinar√°n los resultados obtenidos a partir de los cl√∫sters y anomal√≠as generadas. ¬øSe logra una separaci√≥n efectiva de los datos? Entregue una interpretaci√≥n de lo que representa cada cl√∫ster y anomal√≠a.\n",
    "5. Conclusi√≥n\n",
    "    - Se resumir√°n las principales conclusiones del an√°lisis y se destacar√°n las implicaciones pr√°cticas de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
